{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cabicho/ds_in_deploy/blob/modulo08_hyperparameter_fine_tuning/m04_v01_h6_store_sales_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SFbO_3n5FwB4"
      },
      "source": [
        "# Instalations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4gVmCkFGIug",
        "outputId": "d8dbae59-7f3d-4c49-bc58-2ad065db6660"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sklearn\n",
            "  Downloading sklearn-0.0.post12.tar.gz (2.6 kB)\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
            "\u001b[31m╰─>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for details.\n",
            "Collecting inflection==0.5.1\n",
            "  Downloading inflection-0.5.1-py2.py3-none-any.whl (9.5 kB)\n",
            "Installing collected packages: inflection\n",
            "Successfully installed inflection-0.5.1\n",
            "Collecting boruta\n",
            "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.6/56.6 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from boruta) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from boruta) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from boruta) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->boruta) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.17.1->boruta) (3.4.0)\n",
            "Installing collected packages: boruta\n",
            "Successfully installed boruta-0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install sklearn\n",
        "!pip install inflection==0.5.1\n",
        "#!pip install import-ipynb==0.1.4\n",
        "!pip install boruta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "3AkzFyBHI0Gq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j4TXRztkGYFZ",
        "outputId": "d1aaf293-f39a-4617-85a5-b2c5223ed1f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sklearn-pandas==2.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep sklearn #sklearn-pandas==2.2.0\n",
        "#!pip freeze | gre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51QX-OxkIhgs",
        "outputId": "8eb1f7c4-45c9-4b47-c493-ae5973feaf9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inflect==7.0.0\n",
            "inflection==0.5.1\n"
          ]
        }
      ],
      "source": [
        "!pip freeze | grep inflec #inflect==7.0.0 inflection==0.5.1\n",
        "!pip freeze | grep import-ipynb\n",
        "!pip freeze | grep import-ipynb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8_Ql6npdiC-"
      },
      "source": [
        "# 0.0 IMPORTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "V2zzLCzHeS1c",
        "outputId": "4175616e-b6c4-4acd-afce-052e1e022dfc"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "Error: credential propagation was unsuccessful",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    101\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    131\u001b[0m   )\n\u001b[1;32m    132\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvfQyu9sdiDN"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "#!pip install inflection\n",
        "import inflection\n",
        "import math\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.style.use('seaborn-white')\n",
        "import datetime\n",
        "#import import-ipynb #import-ipynb\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# import matplotlib.gridspec # as gridspec\n",
        "# H4. Lojas com promoções activas por mais tempo, com + dias de promoção, deveriam vender + *\n",
        "from  matplotlib.gridspec   import GridSpec # as gridspec, ModuleNotFoundError: No module named 'matplotlib.gridspec.GridSpec'; 'matplotlib.gridspec' is not a package\n",
        "\n",
        "from IPython.core.display   import HTML\n",
        "from IPython.display        import Image\n",
        "#%matplotlib inline\n",
        "from boruta                 import BorutaPy\n",
        "\n",
        "from sklearn.preprocessing  import RobustScaler, MinMaxScaler, LabelEncoder #trocando letras por números\n",
        "from sklearn.ensemble       import RandomForestRegressor\n",
        "\n",
        "from sklearn.metrics        import mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model   import LinearRegression, Lasso\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSa6L5ILdiDO"
      },
      "source": [
        "# 0.1 Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UWEvxI9diDP"
      },
      "outputs": [],
      "source": [
        "#import-ipynb\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UrbVwGmCdiDP"
      },
      "source": [
        "## 0.1 Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KQh3fb0wdiDQ"
      },
      "outputs": [],
      "source": [
        "def jupyter_settings():\n",
        "    %matplotlib inline\n",
        "    #%pylab inline\n",
        "\n",
        "    plt.style.use('bmh')\n",
        "    plt.rcParams['figure.figsize']=[25,12]\n",
        "    plt.rcParams['font.size']=24\n",
        "\n",
        "    display(HTML('<style>.container {width:100% !important;}</style>'))\n",
        "    pd.options.display.max_columns = None\n",
        "    pd.options.display.max_rows = None\n",
        "    pd.set_option('display.expand_frame_repr', False)\n",
        "\n",
        "    sns.set()\n",
        "\n",
        "#4.1.3. Categorical Variable\n",
        "def plots(df, n):\n",
        "    #for i to n:\n",
        "    #        plt.subplot(1,n,i+1)\n",
        "    plt.subplot(1,n,1)\n",
        "    sns.countplot(df5['state_holiday'], orient='h' ) # “y” | “h” |“v” |  “x” | “y”\n",
        "\n",
        "    #plt.subplot(1,n,i+1)\n",
        "    plt.subplot(1,n,2)\n",
        "    #label='public holiday'\n",
        "    #sns.kdeplot(df4[df4['state_holiday']==label]['sales'], label=label, shade=True) #'Easter holiday, Christmas\n",
        "    # `shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
        "    #This will become an error in seaborn v0.14.0; please update your code.\n",
        "    #for i in\n",
        "    #import numpy.dtype\n",
        "    for i in range(len(df4.state_holiday.unique())): # identificando o tamanho da lista\n",
        "        if df4.state_holiday.unique()[i]!='regular_day': # verificando o valor do indice\n",
        "            #print(df4.state_holiday.unique()[i]) #visualizando o valor\n",
        "            label=df4.state_holiday.unique()[i]\n",
        "            #df4.state_holiday.unique()[i]\n",
        "            #sns.kdeplot(df4[df==label]['sales'], label=label, fill=True) #'Easter holiday, Christmas\n",
        "            #sns.kdeplot(df4[df==int(df4.state_holiday.unique()[i])]['sales'], label=label, fill=True)\n",
        "\n",
        "            #np.dtype(df4.state_holiday.unique()[i]) # TypeError: data type 'public holiday' not understood\n",
        "            #label=df4.state_holiday.unique()[i] #'public holiday'\n",
        "            sns.kdeplot(df4[df4['state_holiday']==label]['sales'], label=label, fill=True)\n",
        "            print(label)\n",
        "    #o grafico sobreposto e transparente facilita a observação do pico e largura na distribuição das variáveis\n",
        "    # visualizando as distribuições sobre postas\n",
        "\n",
        "# 7.0. PASSO 07 - MACHINE LEARNING MODELLING\n",
        "def mean_absolute_percentage_error(y, yhat):\n",
        "  return np.mean(np.abs((y-yhat)/y))\n",
        "\n",
        "def ml_error(model_name, y, yhat):\n",
        "  mae= mean_absolute_error(y, yhat)\n",
        "  mape= mean_absolute_percentage_error(y, yhat)\n",
        "  rmse= np.sqrt(mean_squared_error(y, yhat))\n",
        "\n",
        "  return pd.DataFrame({'Model Name' : model_name,\n",
        "                       'MAE'        : mae,\n",
        "                       'MAPE'       : mape,\n",
        "                       'RMSE'       : rmse },\n",
        "                      index=[0])\n",
        "\n",
        "# Modulo 7, - MACHINE LEARNING MODELLING\n",
        "def cross_validation(x_training, kfold, model_name, model): #(x_training, kfold): #try_go():\n",
        "\n",
        "  day_=x_training[['date','store']].groupby('store').max().reset_index()['date'][0]\n",
        "  print('Date in database: {}, periodo of time: {}'.format(day_, datetime.timedelta(days=6*7)))\n",
        "\n",
        "  mae_list, mape_list, rmse_list = [],[],[]\n",
        "\n",
        "  #filtering dataset\n",
        "  for k in range(1,kfold+1): #6): # reversed(range(1,6)):\n",
        "    #max_date_train_or_start_validation\n",
        "    validation_start_date=day-datetime.timedelta(days=k*6*7)\n",
        "    validation_end_date=day-datetime.timedelta(days=(k-1)*6*7)\n",
        "\n",
        "    #validation_start_date=max_date_train_\n",
        "    max_date_train_ = day-datetime.timedelta(days=k*6*7)\n",
        "    #max_date_train_ = day-datetime.timedelta(days=k*6*7)\n",
        "    print(max_date_train_) #[0] # = min_date_test Timestamp('2012-11-20 00:00:00')\n",
        "\n",
        "    # filtering/training dataset\n",
        "    training = x_training[x_training['date']< validation_start_date]#[cols_selected_boruta] #max_date_train_]\n",
        "    validation = x_training[(x_training['date']>= validation_start_date)&(x_training['date']< validation_end_date)]#[cols_selected_boruta]\n",
        "    # df6_train_ = df6[df6['date']< max_date_train_] #df6['date']< '2015-06-05'] #max_date_train\n",
        "    # df6[df6_train].sample()\n",
        "    # print(df6_train_.sample(1)) #608130, 969198\n",
        "\n",
        "    #training and validation dataset\n",
        "\n",
        "    #training dataset\n",
        "    xtraining = training.drop(['date','sales'], axis=1) #removing colluns that can be into to the training\n",
        "    ytraining = training.sales\n",
        "\n",
        "    #print('xtraining.sample()', xtraining.sample())\n",
        "\n",
        "    #validation dataset\n",
        "    xvalidation = validation.drop(['date','sales'], axis=1) #removing colluns that can be into to the training\n",
        "    yvalidation = validation.sales\n",
        "\n",
        "    #print('xvalidation.sample()', xvalidation.sample())\n",
        "    #X_train_ = df6_train_.copy()\n",
        "    #y_train_ = X_train_['sales']\n",
        "\n",
        "    #model\n",
        "    #print(xtraining.dtypes)\n",
        "    #model='Linear Regression'\n",
        "    #lr = LinearRegression().fit(xtraining, ytraining)\n",
        "    #\n",
        "    m = model.fit(xtraining, ytraining)\n",
        "\n",
        "    #prediction\n",
        "    #yhat_lr=lr.predict(xvalidation)\n",
        "    yhat=m.predict(xvalidation)\n",
        "\n",
        "    #performance, model_name, 'Linear Regression'\n",
        "    #lr_result = ml_error(model_name, np.expm1(yvalidation), np.expm1(yhat_lr))\n",
        "    m_result = ml_error(model_name, np.expm1(yvalidation), np.expm1(yhat))\n",
        "    #print(lr_result)\n",
        "    print(m_result)\n",
        "\n",
        "    #mae_list.append(lr_result['MAE'])\n",
        "    mae_list.append(m_result['MAE'])\n",
        "    #mape_list.append(lr_result['MAPE'])\n",
        "    mape_list.append(m_result['MAPE'])\n",
        "    #rmse_list.append(lr_result['RMSE'])\n",
        "    rmse_list.append(m_result['RMSE'])\n",
        "\n",
        "    #print('Train_ Min Date: {}'.format(xvalidation['date'].min()['date']))\n",
        "    #print('Train_ Max Date: {}'.format(xvalidation.date.max()['date']))\n",
        "  return pd.DataFrame(\n",
        "      { 'Model Name': model_name,\n",
        "        'MAE CV':  np.round( np.mean(mae_list), 2).astype(str) + ' +/- ' + np.round( np.std(mae_list), 2).astype(str),\n",
        "        'MAE_CV':  ' [ ' + np.round( np.mean(mae_list) - np.std(mae_list), 2).astype(str) + ' -- ' + np.round( np.mean(mae_list) + np.std(mae_list), 2).astype(str) + ' ] ',\n",
        "        'MAPE CV':  np.round( np.mean(mape_list), 2).astype(str) + ' +/- ' + np.round( np.std(mape_list), 2).astype(str),\n",
        "        'MAPE_CV':  ' [ ' + np.round( np.mean(mape_list) - np.std(mape_list), 2).astype(str) + ' -- ' + np.round( np.mean(mape_list) + np.std(mape_list), 2).astype(str) + ' ] ',\n",
        "        'RMSE CV':  np.round( np.mean(rmse_list), 2).astype(str) + ' +/- ' + np.round( np.std(rmse_list), 2).astype(str),\n",
        "        'RMSE_CV': ' [ ' + np.round( np.mean(rmse_list) - np.std(rmse_list), 2).astype(str) + ' -- ' + np.round( np.mean(rmse_list) + np.std(rmse_list), 2).astype(str) + ' ] '},\n",
        "       index=[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edm8sRErdiDR"
      },
      "outputs": [],
      "source": [
        "jupyter_settings()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJYFGfOndiDS"
      },
      "source": [
        "# 0.2 Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wf1l4PYRdiDW"
      },
      "outputs": [],
      "source": [
        "#df_train_raw=pd.read_csv(\"../ds/data_set/data/train.csv\", low_memory=False)\n",
        "#df_train_raw=pd.read_csv(\"/dataset/data/train.csv\", low_memory=False)\n",
        "df_train_raw=pd.read_csv(\"/content/drive/MyDrive/dataset/train.csv\", low_memory=False)\n",
        "\n",
        "#df_store_raw=pd.read_csv(\"../ds/data_set/data/store.csv\", low_memory=False)\n",
        "df_store_raw=pd.read_csv(\"/content/drive/MyDrive/dataset/store.csv\", low_memory=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CojaLdztdiDX"
      },
      "outputs": [],
      "source": [
        "df_train_raw.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syQk-q_bdiDX"
      },
      "outputs": [],
      "source": [
        "df_store_raw.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-Wl__2mdiDY"
      },
      "outputs": [],
      "source": [
        "df_train_raw.shape #(1001599, 10)\n",
        "df_train_raw.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5YmolWt_diDY"
      },
      "outputs": [],
      "source": [
        "df_store_raw.shape #(1115, 10)\n",
        "df_store_raw.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5PPWPc_diDZ"
      },
      "outputs": [],
      "source": [
        "#df_sales_raw # 1001599 rows × 10 columns\n",
        "df_store_raw # 1115 rows × 10 columns\n",
        "\n",
        "# arquivo_referencia, anexado a referencia, como faremos o merge, a coluna igual nos dois\n",
        "df_raw=pd.merge(df_train_raw, df_store_raw, how='left', on='Store') #1001599 rows × 19 columns\n",
        "\n",
        "# so alterou o numero de colunas\n",
        "df_raw.shape #(1001599, 19)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nU9ccxsudiDa"
      },
      "outputs": [],
      "source": [
        "df_raw.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HWnH2oL9diDa"
      },
      "source": [
        "# 1.0. PASSO 01 - DESCRIÇÃO DOS DADOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfOJhyWydiDb"
      },
      "source": [
        "## 1.1 Rename Columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q7mR63vediDb"
      },
      "outputs": [],
      "source": [
        "# fazendo uma copia da seccao anterior\n",
        "df1=df_raw.copy()\n",
        "#list(df1.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ocF2oaUdiDb"
      },
      "outputs": [],
      "source": [
        "cols_old=list(df1.columns)\n",
        "cols_old #.list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sYo0xEsLdiDc"
      },
      "outputs": [],
      "source": [
        "snakecase = lambda x: inflection.underscore(x)\n",
        "#mapeando a função\n",
        "cols_new = list(map(snakecase, cols_old))\n",
        "#rename\n",
        "df1.columns=cols_new\n",
        "#cols_new"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3ACdY9DdiDc"
      },
      "source": [
        "## 1.2 Data Dimensions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qB969lPdiDc"
      },
      "outputs": [],
      "source": [
        "print('Number of Rows: {}'.format(df1.shape[0]))\n",
        "print('Number of Cols: {}'.format(df1.shape[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOPbAoAqdiDd"
      },
      "source": [
        "## 1.3 Data Types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2-FyMJvjdiDd"
      },
      "outputs": [],
      "source": [
        "df1.dtypes\n",
        "df1['date']=pd.to_datetime(df1['date'])\n",
        "#df1.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpNunG69diDe"
      },
      "source": [
        "## 1.4 Check NA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nrRRZ-HzdiDe"
      },
      "outputs": [],
      "source": [
        "df1.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zkQV-hOdiDe"
      },
      "source": [
        "## 1.5 Fillout NA"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TagS2wYBdiDe"
      },
      "outputs": [],
      "source": [
        "df1.sample().T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8r0VfMPkdiDf"
      },
      "outputs": [],
      "source": [
        "atributo='competition_open_since_month'\n",
        "df1[atributo]= df1.apply(lambda x: x['date'].month if math.isnan(x[atributo]) else x[atributo], axis=1) #axis=1 aplicando ao longo das colunas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RX63bEgdiDf"
      },
      "outputs": [],
      "source": [
        "atributo='competition_open_since_year'\n",
        "df1[atributo]= df1.apply(lambda x: x['date'].year if math.isnan(x[atributo]) else x[atributo], axis=1) #axis=1 aplicando ao longo das colunas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V12LobUdiDf"
      },
      "outputs": [],
      "source": [
        "atributo='promo2_since_week'\n",
        "df1[atributo]= df1.apply(lambda x: x['date'].week if math.isnan(x[atributo]) else x[atributo], axis=1) #axis=1 aplicando ao longo das colunas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8c1VbiqdiDg"
      },
      "outputs": [],
      "source": [
        "atributo='promo2_since_year'\n",
        "df1[atributo]= df1.apply(lambda x: x['date'].year if math.isnan(x[atributo]) else x[atributo], axis=1) #axis=1 aplicando ao longo das colunas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "al1w5C-ddiDg"
      },
      "outputs": [],
      "source": [
        "#competition_distance              2600\n",
        "#print(df1[1])\n",
        "#df1['competition_distance'] =df1['competition_distance'].apply(lambda x: 200000.0 if math.isnan(x) else x)\n",
        "\n",
        "#competition_open_since_month    318392\n",
        "# se for verdade extraimos o mes\n",
        "df1['competition_open_since_month'] = df1.apply(lambda x: x['date'].moth if math.isnan( x['competition_open_since_month']) else x['competition_open_since_month'], axis=1)\n",
        "print('done')\n",
        "df1.sample(10)\n",
        "#competition_open_since_year     318392\n",
        "#atributo='competition_open_since_year'\n",
        "#df1[atributo] = df1.apply(lambda x: x['date'].year if math.isnan( x['competition_open_since_year']) else x['competition_open_since_year'], axis=1)\n",
        "\n",
        "#promo2_since_week               500415\n",
        "#promo2_since_year               500415\n",
        "#promo_interval                  500415"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sqf2ms5RdiDg"
      },
      "outputs": [],
      "source": [
        "#promo_interval                  500415\n",
        "month_map = {1:'Jan', 2:'Fev', 3:'Mar', 4:'Apr', 5:'May', 6:'Jun', 7:'Jul', 8:'Aug', 9:'Sep', 10:'Oct', 11:'Nov', 12:'Dec'}\n",
        "df1['promo_interval'].fillna(0, inplace=True) # fazendo modificação directa na coluna\n",
        "#criando a coluna month_map, que indica o mês que ocorreu a venda\n",
        "df1['month_map'] = df1['date'].dt.month.map(month_map) # os numeros serão trocados pelas letras\n",
        "# A venda foi realizada num mês promocional\n",
        "df1['is_promo'] = df1[['promo_interval', 'month_map']].apply(lambda x: 0 if x['promo_interval'] == 0 else 1 if x['month_map'] in x['promo_interval'].split(',') else 0, axis=1)\n",
        "# criando lista dos elementos da coluna promo_interval e verificar se month_map está dentro da lista do intervalo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N4ghfnRJdiDo"
      },
      "outputs": [],
      "source": [
        "df1[['date', 'month_map']].sample(12)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8TEf5YidiDo"
      },
      "source": [
        "## 1.6 Check Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvHzF1EIdiDo"
      },
      "outputs": [],
      "source": [
        "df1.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5dZKYmYediDp"
      },
      "outputs": [],
      "source": [
        "\n",
        "#competition_open_since_month           float64\n",
        "atributo='competition_open_since_month'\n",
        "df1[atributo]=df1[atributo].astype(int)\n",
        "#competition_open_since_year            float64\n",
        "atributo='competition_open_since_year'\n",
        "df1[atributo]=df1[atributo].astype(int)\n",
        "#promo2_since_week                      float64\n",
        "atributo='promo2_since_week'\n",
        "df1[atributo]=df1[atributo].astype(int)\n",
        "#promo2_since_year                      float64\n",
        "atributo='promo2_since_year'\n",
        "df1[atributo]=df1[atributo].astype(int)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGuRD-fvdiDp"
      },
      "source": [
        "## 1.7 Descriptive Statistical, ganhando conhecimento do negocio e detectar alguns erros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPMCLq5GdiDp"
      },
      "outputs": [],
      "source": [
        "num_attributes = df1.select_dtypes(include=['int64', 'float64']) # todos os atributos sao de variavel numerica\n",
        "cat_attributes = df1.select_dtypes(exclude=['int64', 'float64', 'datetime64[ns]']) #include=['object']\n",
        "obj_attributes = df1.select_dtypes(include=['object']) #include=['object']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_KSVogLdiDq"
      },
      "outputs": [],
      "source": [
        "#cat_attributes.sample(2)\n",
        "#if (cat_attributes == obj_attributes):\n",
        "#  print('True')\n",
        "#else:\n",
        "#  print('False')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LJXQAGGidiDu"
      },
      "outputs": [],
      "source": [
        "obj_attributes.sample(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s784zpsZdiDv"
      },
      "outputs": [],
      "source": [
        "num_attributes.sample() #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED55KdHCdiDw"
      },
      "outputs": [],
      "source": [
        "# Central tendency - mean, median\n",
        "# Dispersion - std, min, max, range, skew, kurtosis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ymo6Uu_SdiDw"
      },
      "source": [
        "### 1.7.1 Numerical Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DnnH0T28diDw"
      },
      "outputs": [],
      "source": [
        "# Central tendency - mean, median\n",
        "ct1 = pd.DataFrame( num_attributes.apply(np.mean) ).T\n",
        "ct2 = pd.DataFrame( num_attributes.apply(np.median) ).T\n",
        "\n",
        "# Dispersion - std, min, max, range, skew, kurtosis\n",
        "d1=pd.DataFrame(num_attributes.apply(np.std)).T\n",
        "d2=pd.DataFrame(num_attributes.apply(min)).T\n",
        "d3=pd.DataFrame(num_attributes.apply(max)).T\n",
        "d4=pd.DataFrame(num_attributes.apply(lambda x: x.max()-x.min())).T\n",
        "d5=pd.DataFrame(num_attributes.apply(lambda x: x.skew())).T\n",
        "d6=pd.DataFrame(num_attributes.apply(lambda x: x.kurtosis())).T\n",
        "\n",
        "# Concatenate\n",
        "m = pd.concat([d2, d3, d4, ct1, ct2, d1, d5, d6]).T.reset_index()\n",
        "#nomeando os atributos, as colunas\n",
        "m.columns=['attributes','min','max','range','mean','median','std','skew','kurtosis']\n",
        "m"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nv02Kl5DdiDx"
      },
      "outputs": [],
      "source": [
        "#sns.distplot(df1['sales']) #`distplot` is a deprecated function and will be removed in seaborn v0.14.0.\n",
        "sns.displot(df1['sales'])\n",
        "sns.displot(df1['competition_distance'])\n",
        "!pip freeze | grep seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjN_FJF9diDx"
      },
      "source": [
        "### 1.7.2 Categorial Attributes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZxFIuvNdiDy"
      },
      "outputs": [],
      "source": [
        "#Quantos niveis cada variável categorica tem? Como aplicar 1 função em todas as colunas?\n",
        "cat_attributes.apply(lambda x: x.unique().shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pv2g6czdiDz"
      },
      "outputs": [],
      "source": [
        "#Quantos niveis cada variável categorica tem? Como aplicar 1 função em todas as colunas?\n",
        "cat_attributes.apply(lambda x: x.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kd8ccrGddiDz"
      },
      "outputs": [],
      "source": [
        "# a dimensão das variáveis está muito diferente\n",
        "# provavel razão, dias fechado tendo vendas igual a zero"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMv_pBaZdiDz"
      },
      "outputs": [],
      "source": [
        "aux1=df1[(df1['state_holiday']!=0) & (df1['sales']>0)]\n",
        "sns.boxplot(x='state_holiday', y='sales', data=df1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lg5KbNjYdiD0"
      },
      "outputs": [],
      "source": [
        "aux1=df1[(df1['state_holiday']!='0') & (df1['sales']>0) & (df1['sales']<25000)] #dia diferente do feriado e com vendas acima de zero\n",
        "\n",
        "plt.subplot(1,7,1) #1 linha, 3 colunas, na posicão 1\n",
        "sns.boxplot(x='state_holiday', y='sales', data=aux1)\n",
        "\n",
        "plt.subplot(1,7,4) #1 linha, 3 colunas, na posicão 2\n",
        "sns.boxplot(x='store_type', y='sales', data=aux1)\n",
        "\n",
        "plt.subplot(1,7,7) #1 linha, 3 colunas, na posicão 1\n",
        "sns.boxplot(x='assortment', y='sales', data=aux1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRvYZktMdiD1"
      },
      "source": [
        "# 2.0. PASSO 02 - FEATURE ENGINEERING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1_NFVSUdiD2"
      },
      "outputs": [],
      "source": [
        "df2=df1.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L2JY3pNpdiD2"
      },
      "source": [
        "## 2.1. Mapa Mental de Hipoteses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoVmIsD6diD2"
      },
      "outputs": [],
      "source": [
        "Image('img/MindMapHipoteses_m03.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZkO89h_diD3"
      },
      "source": [
        "## 2.1. Criação de Hipoteses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BN-Vtt2adiD3"
      },
      "source": [
        "### 2.1.1. Hipóteses Loja"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp3OfJ6TdiD3"
      },
      "source": [
        "** 1.** Lojas com maior quadro de funcionários deveriam vender mais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qznlfMDVdiD3"
      },
      "source": [
        "** 1. ** Lojas com maior estoque deveriam vender mais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_i_HWandiD4"
      },
      "source": [
        "**1.** Lojas com porte maior deveriam vender mais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htSFms83diD4"
      },
      "source": [
        "**1.** Lojas com menor porte deveriam vender menos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptKJjxi9diD4"
      },
      "source": [
        "**1.** Lojas com maior sortimento deveriam vender mais."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_S-PxracdiD4"
      },
      "source": [
        "### 2.1.2. Hipóteses Produto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArPz6j-IdiD4"
      },
      "source": [
        "**1.** Lojas que investem mais em Marketing deveriam vender mais.\n",
        "\n",
        "**2.** Lojas com maior exposição de produtos nas vitrines deveriam vender mais.\n",
        "\n",
        "**3.** Lojas com produtos com preços menores deveriam vender mais.\n",
        "\n",
        "**4.** Lojas com promoções mais agressivas (descontos maiores), deveriam vender mais.\n",
        "\n",
        "**5.** Lojas com promoções activas por mais tempo deveriam vender mais.\n",
        "\n",
        "**6.** Lojas com + dias de promoção deveriam vender +.\n",
        "\n",
        "**4.** Lojas que tem preços menores por mais tempo nos produtos deveriam vender mais.\n",
        "\n",
        "**5.** Lojas com + promoções consecutivas deveriam vender +."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMJzTkHfdiD4"
      },
      "source": [
        "### 2.1.3. Hipóteses Tempo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSrkq8KTdiD4"
      },
      "source": [
        "**1.** Lojas abertas durante o feriado de Natal deveriam vender menos.\n",
        "\n",
        "**1.** Lojas ao longo do ano deveriam vender mais.\n",
        "\n",
        "**1.** Lojas no segundo semestre do ano deveriam vender mais.\n",
        "\n",
        "**1.** Lojas depois do dia 10 de cada mes deveriam vender mais.\n",
        "\n",
        "**1.** Lojas nos finais de semana deveriam vender menos.\n",
        "\n",
        "**1.** Lojas nos Feriados escolares deveriam vender menos.\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "265VeFaodiD5"
      },
      "source": [
        "## 2.2. Lista Final de Hipóteses"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0MqAkRBdiD5"
      },
      "source": [
        "**[1., 3.]** Lojas com [maior sortimento/ competidores à + tempo]  deveriam vender +."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIcxYFQHdiD5"
      },
      "source": [
        "**[2., ]** Lojas com competidores + próximo deveriam vender - ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QmBOrVEMdiD5"
      },
      "source": [
        "** Produtos **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rHzaoMndiD9"
      },
      "source": [
        "**[4., 5., 6.]** Lojas [promoções activas por mais tempo, com + [dias de promoção, promoções consecutivas]]  deveriam vender +"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NI9SmvyfdiD9"
      },
      "source": [
        "** Tempo **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF8YUa6VdiD-"
      },
      "source": [
        "**7.** Lojas abertas durante o feriado de Natal deveriam vender menos.\n",
        "\n",
        "**8.** Lojas ao longo do ano deveriam vender mais.\n",
        "\n",
        "**9.** Lojas no segundo semestre do ano deveriam vender mais.\n",
        "\n",
        "**10.** Lojas depois do dia 10 de cada mes deveriam vender mais.\n",
        "\n",
        "**11.** Lojas nos finais de semana deveriam vender menos.\n",
        "\n",
        "**12.** Lojas nos Feriados escolares deveriam vender menos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ydqm5yegdiD-"
      },
      "source": [
        "## 2.3. Feature Engineeringn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E1XHUEFCdiD_"
      },
      "outputs": [],
      "source": [
        "df2.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QjMm6aHIdiD_"
      },
      "outputs": [],
      "source": [
        "# year\n",
        "df2['year']=df2['date'].dt.year\n",
        "\n",
        "# month\n",
        "df2['month']=df2['date'].dt.month\n",
        "\n",
        "# day\n",
        "df2['day']=df2['date'].dt.day\n",
        "\n",
        "# week of year\n",
        "# df2['week_of_year']=df2['date'].dt.weekofyear #AttributeError: 'DatetimeProperties' object has no attribute 'weekofyear'\n",
        "# Deprecated since version 1.1.0.\n",
        "#https://pandas.pydata.org/pandas-docs/version/1.3/reference/api/pandas.Series.dt.weekofyear.html\n",
        "\n",
        "#df2['week_of_year']=df2['date'].dt.isocalendar()\n",
        "#df2['week_of_year']=df2['date'].dt.isocalendar().week\n",
        "\n",
        "#df2['week_of_year']=df2['date'].dt.week #AttributeError: 'DatetimeProperties' object has no attribute 'week'\n",
        "\n",
        "# year week\n",
        "df2['year_week']=df2['date'].dt.strftime('%Y-%W') #AttributeError: 'DatetimeProperties' object has no attribute 'srtftime'\n",
        "df2['year_week'].sample(5)\n",
        "# competition since\n",
        "#competition_open_since_month\tcompetition_open_since_year\n",
        "year='competition_open_since_year'\n",
        "month='competition_open_since_month'\n",
        "# considerou-se que o primeiro dia do mes, o dia que iniciou a competição #tempo desde que a competição começou em meses\n",
        "df2['competition_open_since']=df2.apply( lambda x: datetime.datetime(year=x[year],month=x[month],day=1), axis=1)\n",
        "df2['competition_time_month']=((df2['date']-df2['competition_open_since'])/30).apply(lambda x: x.days).astype(int)\n",
        "df2['competition_time_month'].sample()\n",
        "\n",
        "# promo since\n",
        "# promo2_since_week\tpromo2_since_year\n",
        "\n",
        "# assortment\n",
        "# state holiday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNqCHqiJdiD_"
      },
      "outputs": [],
      "source": [
        "# promo since\n",
        "# promo2_since_week\tpromo2_since_year\n",
        "df2['promo_since'] = df2['promo2_since_year'].astype(str) + '-' + df2['promo2_since_week'].astype(str)\n",
        "df2['promo_since'].sample()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TF-cxM9FdiEA"
      },
      "outputs": [],
      "source": [
        "#passando a campo 'promo_since' de string para datetime64\n",
        "df2['promo_since']=df2['promo_since'].apply(lambda x: datetime.datetime.strptime(x + '-1', '%Y-%W-%w') - datetime.timedelta(days=7))\n",
        "\n",
        "df2['promo_since'].sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vyXI9D32diEB"
      },
      "outputs": [],
      "source": [
        "# calculando o tempo, em semanas, desde que a promoção está activa, entre duas datas\n",
        "# sinal negativo, vendas no período tradicional da promoção\n",
        "# sinal positivo, vendas no período extendido da promoção\n",
        "df2['promo_time_week']=((df2['date']-df2['promo_since'])/7).apply(lambda x: x.days).astype(int)\n",
        "df2['promo_time_week'].sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yq-tOmYMdiEB"
      },
      "outputs": [],
      "source": [
        "# assortment\n",
        "\n",
        "df2['assortment']=df2['assortment'].apply(lambda x: 'basic' if x == 'a' else 'extra' if x=='b' else 'extended')\n",
        "df2['assortment'].sample(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5EGUptDdiEC"
      },
      "outputs": [],
      "source": [
        "df2['state_holiday'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgIAUo2WdiEC"
      },
      "outputs": [],
      "source": [
        "# state holiday\n",
        "# a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
        "df2['state_holiday']=df2['state_holiday'].apply(lambda x: 'public holiday' if x=='a' else 'Easter holiday' if x=='b'  else 'Christmas' if x=='c' else 'regular_day')\n",
        "df2['state_holiday'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oorEli6cdiEC"
      },
      "source": [
        "# 3.0. PASSO 03 - FILTRAGEM DE VARIÁVEIS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XDSmwMsdiED"
      },
      "outputs": [],
      "source": [
        "df3=df2.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g0_lM6gediED"
      },
      "outputs": [],
      "source": [
        "df3['assortment'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jktE8GMKdiED"
      },
      "outputs": [],
      "source": [
        "df3.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7s1oi9zzdiED"
      },
      "source": [
        "## 3.1 Filtragem das linhas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_B2_MI0ZdiEE"
      },
      "outputs": [],
      "source": [
        "df3 = df3[( df3['open'] != 0) & (df3['sales']>0)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzEmEV0WdiEE"
      },
      "source": [
        "## 3.2 Seleção das colunas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gHb_kCUHdiEE"
      },
      "outputs": [],
      "source": [
        "cols_drop = ['customers', 'open', 'promo_interval', 'month_map']\n",
        "df3 = df3.drop(cols_drop, axis=1) #axis=1 são colunas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yufh4UuqdiEE"
      },
      "outputs": [],
      "source": [
        "df3.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMcwVztudiEF"
      },
      "source": [
        "# 4.0. PASSO 04 - ANÁLISE EXPLORATÓRIA DE DADOS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuY2A8vWdiEG"
      },
      "source": [
        "### 4.1. Análise Univariada"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dU2MzBBldiEH"
      },
      "outputs": [],
      "source": [
        "df4 = df3.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcxeiPG_diEH"
      },
      "outputs": [],
      "source": [
        "df4['assortment'].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVc2CDdCdiEI"
      },
      "source": [
        "#### 4.1.1. Response Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pempQi0NdiEI"
      },
      "outputs": [],
      "source": [
        "sns.displot(df4['sales'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE7ydKh_diEI"
      },
      "outputs": [],
      "source": [
        "sns.displot(df4['sales'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6FG9lVjWdiEI"
      },
      "outputs": [],
      "source": [
        "sns.distplot(np.log(df4['sales']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OzhorytudiEJ"
      },
      "source": [
        "#### 4.1.2. Numerical Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OqwegOYdiEJ"
      },
      "outputs": [],
      "source": [
        "num_attributes.hist(bins=25)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D17kPssvdiEJ"
      },
      "outputs": [],
      "source": [
        "cat_attributes.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_eWl9xLdiEK"
      },
      "outputs": [],
      "source": [
        "df4['state_holiday'].drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wii_GkAjdiEK"
      },
      "outputs": [],
      "source": [
        "#df4[df4['state_holiday']!='public holiday']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKBqm7ZPdiEK"
      },
      "outputs": [],
      "source": [
        "#sns.countplot(df4['state_holiday'], orient='v')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioyedFkzdiEN"
      },
      "outputs": [],
      "source": [
        "#state_holiday,store_type,assortment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRYsp1UpdiEN"
      },
      "source": [
        "#### 4.1.3. Categorical Variable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HAJP2CgXdiEO"
      },
      "outputs": [],
      "source": [
        "df4['state_holiday'].drop_duplicates()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ2YRO52diEO"
      },
      "outputs": [],
      "source": [
        "df4['state_holiday'].sample(4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "99V_JMmYdiEP"
      },
      "outputs": [],
      "source": [
        "df4[(df4['state_holiday']!='regular_day')&(df4['state_holiday']!='public holiday')&(df4['state_holiday']!='Easter holiday')].sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNZmYFkndiEP"
      },
      "outputs": [],
      "source": [
        "df5=df4[df4['state_holiday'] != 'regular_day']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCujld2wdiEP"
      },
      "outputs": [],
      "source": [
        "# lista diferente de 'regular_day'\n",
        "df5.state_holiday.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqt6GPt8diEQ"
      },
      "outputs": [],
      "source": [
        "#recebendo o tamanho da lista\n",
        "for i in range(len(df4.state_holiday.unique())): # identificando o tamanho da lista\n",
        "    if df4.state_holiday.unique()[i]!='regular_day': # verificando o valor do indice\n",
        "        print(df4.state_holiday.unique()[i]) #visualizando o valor\n",
        "        print (i) # mostrando o indice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyv3u7bVdiEQ"
      },
      "outputs": [],
      "source": [
        "plots(df4['state_holiday'], 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s2u8pP8xdiER"
      },
      "outputs": [],
      "source": [
        "#no primeiro plot não visualizo a categoria Christmas no grafico\n",
        "#no segundo plot não visualiza a legenda das categorias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Fj89YK0diER"
      },
      "outputs": [],
      "source": [
        "#df4[df4['state_holiday']==label]['sales']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZTOYeNDdiES"
      },
      "outputs": [],
      "source": [
        "#public_holiday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2oj8FMXdiES"
      },
      "outputs": [],
      "source": [
        "df5.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RThOHMmLdiES"
      },
      "outputs": [],
      "source": [
        "# to remove\n",
        "#plot(df4['state_holiday'],\n",
        "#def plot(df,\n",
        "#a = df4[df4['state_holiday']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "###a = df4[df4['state_holiday']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "###plt.subplot(1,2,1)\n",
        "###sns.countplot(a.state_holiday, orient='h') #orient=None , “v” | “h” | “x” | “y”\n",
        "###a.state_holiday.unique()\n",
        "# não apresenta informação de 'Christmas'] no grafico\n",
        "\n",
        "###plt.subplot(1,2,2)\n",
        "###for i in range(len(df4.state_holiday.unique())):\n",
        "    #grafico com as\n",
        "    ###label=df4.state_holiday.unique()[i]\n",
        "\n",
        "    ###if label != 'regular_day':\n",
        "        #print(df4.state_holiday.unique()[i])\n",
        "        ###sns.kdeplot(df4[df4['state_holiday']==label]['sales'], label=label, fill=True)\n",
        "        #print(i)\n",
        "# o grafico 1,\n",
        "# o grafico 2, não visualiza a legenda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fPElIlcWdiET"
      },
      "outputs": [],
      "source": [
        "# to remove\n",
        "##plt.subplot(1,2,2)\n",
        "##label='public holiday'\n",
        "#sns.kdeplot(df4[df4['state_holiday']==label]['sales'], label=label, shade=True) #'Easter holiday, Christmas\n",
        "# `shade` is now deprecated in favor of `fill`; setting `fill=True`.\n",
        "#This will become an error in seaborn v0.14.0; please update your code.\n",
        "##sns.kdeplot(df4[df4['state_holiday']==label]['sales'], label=label, fill=True) #'Easter holiday, Christmas\n",
        "#o grafico sobreposto e transparente facilita a observação do pico e largura na distribuição das variáveis\n",
        "# visualizar as distribuições sobre postas\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCmlggS6diEU"
      },
      "outputs": [],
      "source": [
        "# to remove\n",
        "#plot(df4['state_holiday'],\n",
        "#def plot(df,\n",
        "#a = df4[df4['state_holiday']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "###a = df4[df4['state_holiday']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "###plt.subplot(1,2,1)\n",
        "###sns.countplot(a.state_holiday, orient='h') #orient=None , “v” | “h” | “x” | “y”\n",
        "###a.state_holiday.unique()\n",
        "# não apresenta informação de 'Christmas'] no grafico\n",
        "\n",
        "###plt.subplot(1,2,2)\n",
        "###for i in range(len(df4.state_holiday.unique())):\n",
        "    #grafico com as\n",
        "    ###label=df4.state_holiday.unique()[i]\n",
        "\n",
        "    ###if label != 'regular_day':\n",
        "        #print(df4.state_holiday.unique()[i])\n",
        "       ### sns.kdeplot(df4[df4['state_holiday']==label]['sales'], label=str(label), fill=True)\n",
        "        #print(i)\n",
        "# o grafico 1,\n",
        "# o grafico 2, não visualiza a legenda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hQGl6q_IdiEU"
      },
      "outputs": [],
      "source": [
        "#plot(df4['state_holiday'],\n",
        "#def plot(df,\n",
        "#a = df4[df4['state_holiday']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "a = df4[df4['state_holiday']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(a,x='state_holiday', orient='h') #orient=None , “v” | “h” | “x” | “y”\n",
        "a.state_holiday.unique()\n",
        "# não apresenta informação de 'Christmas'] no grafico\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "for i in range(len(df4.state_holiday.unique())):\n",
        "    #grafico com as\n",
        "    label=df4.state_holiday.unique()[i]\n",
        "\n",
        "    if label != 'regular_day':\n",
        "        #print(df4.state_holiday.unique()[i])\n",
        "        g=sns.kdeplot(df4[df4['state_holiday']==label]['sales'], label=str(label), fill=True)\n",
        "        #print(i)\n",
        "g.legend(loc=\"upper right\")\n",
        "\n",
        "# o grafico 1,\n",
        "# o grafico 2, não visualiza a legenda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exzzKg8cdiEV"
      },
      "outputs": [],
      "source": [
        "# to remove\n",
        "#plot(df4['store_type'],\n",
        "#def plot(df,\n",
        "#a = df4[df4['store_type']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "#a = df4[df4['store_type']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "###plt.subplot(1,2,1)\n",
        "###sns.countplot(df4,x='store_type', orient='h') #orient=None , “v” | “h” | “x” | “y”\n",
        "###a.store_type.unique()\n",
        "# não apresenta informação de 'Christmas'] no grafico\n",
        "\n",
        "###plt.subplot(1,2,2)\n",
        "###for i in range(len(df4.store_type.unique())):\n",
        "    #grafico com as\n",
        "   ### label=df4.state_holiday.unique()[i]\n",
        "\n",
        "    #if label != 'regular_day':\n",
        "        #print(df4.state_holiday.unique()[i])\n",
        "    ###g=sns.kdeplot(df4[df4['store_type']==label]['sales'], label=str(label), fill=True)\n",
        "        #print(i)\n",
        "###g.legend(loc=\"upper right\")\n",
        "\n",
        "# o grafico 1,\n",
        "# o grafico 2, não visualiza a legenda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC_ahjHNdiEW"
      },
      "outputs": [],
      "source": [
        "#plot(df4['store_type'],\n",
        "#def plot(df,\n",
        "#a = df4[df4['store_type']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "#a = df4[df4['assortment']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(df4,x='store_type', orient='h') #orient=None , “v” | “h” | “x” | “y”\n",
        "a.store_type.unique()\n",
        "# não apresenta informação de 'Christmas'] no grafico\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "for i in range(len(df4.store_type.unique())):\n",
        "    #grafico com as\n",
        "    label=df4.store_type.unique()[i]\n",
        "\n",
        "    #if label != 'regular_day':\n",
        "        #print(df4.store_type.unique()[i])\n",
        "    g=sns.kdeplot(df4[df4['store_type']==label]['sales'], label=str(label), fill=True)\n",
        "        #print(i)\n",
        "g.legend(loc=\"upper right\")\n",
        "\n",
        "# o grafico 1,\n",
        "# o grafico 2, não visualiza a legenda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iwpH3SQIdiEX"
      },
      "outputs": [],
      "source": [
        "#plot(df4['assortment'],\n",
        "#def plot(df,\n",
        "#a = df4[df4['assortment']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "#a = df4[df4['assortment']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(df4,x='assortment', orient='h') #orient=None , “v” | “h” | “x” | “y”\n",
        "a.assortment.unique()\n",
        "# não apresenta informação de 'Christmas'] no grafico\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "for i in range(len(df4.assortment.unique())):\n",
        "    #grafico com as\n",
        "    label=df4.assortment.unique()[i]\n",
        "\n",
        "    #if label != 'regular_day':\n",
        "        #print(df4.assortment.unique()[i])\n",
        "    g=sns.kdeplot(df4[df4['assortment']==label]['sales'], label=str(label), fill=True)\n",
        "        #print(i)\n",
        "g.legend(loc=\"upper right\")\n",
        "\n",
        "# o grafico 1,\n",
        "# o grafico 2, não visualiza a legenda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n3w3qtiJdiEY"
      },
      "outputs": [],
      "source": [
        "df4.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HOSAFL8EdiEY"
      },
      "outputs": [],
      "source": [
        "# to remove\n",
        "#store_type\n",
        "#change state_holiday to store_type object\n",
        "#a = df4[df4['store_type']] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "#plt.subplot(1,2,1)# change 1 to second line\n",
        "#plt.subplot(2,2,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHmOWWlVdiEY"
      },
      "outputs": [],
      "source": [
        "# to remove\n",
        "#change state_holiday to store_type object\n",
        "###plt.subplot(1,2,1)\n",
        "###sns.countplot(df4[\"store_type\"], orient='h') #orient=None , “v” | “h” | “x” | “y”\n",
        "#a.state_holiday.unique()\n",
        "# não apresenta informação de 'Christmas' no grafico\n",
        "\n",
        "##plt.subplot(1,2,2) #change 1 to 2\n",
        "#plt.subplot(2,2,2)\n",
        "\n",
        "###plt.subplot(1,2,2)\n",
        "\n",
        "###try_=\"df4.\"  + \"store_type\" + \".unique()\"\n",
        "#for i in range(len(df4.state_holiday.unique())): change state_holiday to store_type#\n",
        "#for i in range(len(df4.store_type.unique())):\n",
        "###for i in range(len(try_)):\n",
        "    #grafico com as\n",
        "    #label=df4.state_holiday.unique()[i] change state_holiday to store_type###\n",
        "    ###label=df4.store_type.unique()[i]\n",
        "\n",
        "    ###if label != 'regular_day':\n",
        "        #print(df4.state_holiday.unique()[i])\n",
        "        #sns.kdeplot(df4[df4['state_holiday']==label]['sales'], label=label, fill=True) change state_holiday to store_type\n",
        "        ###sns.kdeplot(df4[df4['store_type']==label]['sales'], label=label, fill=True)\n",
        "    ###sns.kdeplot(df4[df4['store_type']==label]['sales'], label=label, fill=True)\n",
        "        #print(i)\n",
        "# o grafico 1,\n",
        "# o grafico 2, não visualiza a legenda\n",
        "#assortment                              object\n",
        "#df4.store_type.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dOvF-4vadiEZ"
      },
      "outputs": [],
      "source": [
        "# to remove\n",
        "#store_type\n",
        "#change state_holiday to store_type object\n",
        "####a = df4[df4['store_type']!='regular_day'] #'regular_day' , KeyError: \"None of [Index(['regular_day'\n",
        "#plt.subplot(1,2,1) change 1 to second line\n",
        "####plt.subplot(2,2,1)\n",
        "\n",
        "#change state_holiday to store_type object\n",
        "####sns.countplot(a.store_type, orient='h') #orient=None , “v” | “h” | “x” | “y”\n",
        "#a.state_holiday.unique()\n",
        "# não apresenta informação de 'Christmas'] no grafico\n",
        "\n",
        "#plt.subplot(1,2,2) change 1 to 2\n",
        "####plt.subplot(2,2,2)\n",
        "#for i in range(len(df4.state_holiday.unique())): change state_holiday to store_type\n",
        "####for i in range(len(df4.store_type.unique())):\n",
        "    #grafico com as\n",
        "    #label=df4.state_holiday.unique()[i] change state_holiday to store_type\n",
        "    ####label=df4.store_type.unique()[i]\n",
        "\n",
        "    ####if label != 'regular_day':\n",
        "        #print(df4.state_holiday.unique()[i])\n",
        "        #sns.kdeplot(df4[df4['state_holiday']==label]['sales'], label=label, fill=True) change state_holiday to store_type\n",
        "        ####sns.kdeplot(df4[df4['store_type']==label]['sales'], label=label, fill=True)\n",
        "        #print(i)\n",
        "# o grafico 1,\n",
        "# o grafico 2, não visualiza a legenda\n",
        "#assortment                              object\n",
        "#df4.store_type.unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBt7vXrHdiEZ"
      },
      "source": [
        "### 4.1.3. Categorical Variable, diamonds = sns.load_dataset('diamonds')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0karIWLdiEZ"
      },
      "outputs": [],
      "source": [
        "#https://www.youtube.com/watch?v=8U5h3EJuu8M\n",
        "#Seaborn countplot | What is the countplot? | Seaborn countplot vs barplot\n",
        "diamonds = sns.load_dataset('diamonds')\n",
        "diamonds.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_tazEBMdiEa"
      },
      "outputs": [],
      "source": [
        "diamonds.clarity.isin(['SI1', 'VS2']).shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng1aVHEidiEa"
      },
      "outputs": [],
      "source": [
        "diamonds[diamonds.clarity.isin(['SI1', 'VS2'])].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwH4qXaTdiEb"
      },
      "outputs": [],
      "source": [
        "sns.set_style('darkgrid')\n",
        "plt.subplot(1,2,1)\n",
        "sns.countplot(x='color', data=diamonds)\n",
        "plt.subplot(1,2,2)\n",
        "sns.countplot(x='color', data=diamonds[diamonds.clarity.isin(['SI1', 'VS2'])])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxwxvdBcdiEb"
      },
      "outputs": [],
      "source": [
        "diamonds.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ksIZVs04diEe"
      },
      "outputs": [],
      "source": [
        "plt.subplot(1,3,1)\n",
        "#cut\n",
        "sns.countplot(diamonds.cut) #, orient=\"y\") #orient“v” | “h” | “x” | “y”\n",
        "#color\n",
        "plt.subplot(1,3,2)\n",
        "sns.countplot(diamonds.color) #, orient=\"y\")\n",
        "#diamonds.color.drop_duplicates()\n",
        "diamonds['color'].drop_duplicates()\n",
        "#clarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUGCDI6QdiEe"
      },
      "outputs": [],
      "source": [
        "diamonds.color.cat.categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CN6bZHUvdiEf"
      },
      "outputs": [],
      "source": [
        "diamonds.cut.cat.categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cm8jjZVZdiEf"
      },
      "outputs": [],
      "source": [
        "diamonds.clarity.cat.categories"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONoaim1YdiEf"
      },
      "source": [
        "### 4.2. Análise Bivariada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90CBF88ZIfA8"
      },
      "source": [
        "### **2.2. Lista Final de Hipóteses**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWFRDS4KdiEg"
      },
      "source": [
        "#### **H1. Lojas com maior sortimento deveriam vender mais.**\n",
        "#### **FALSA**, lojas com MAIOR SORTIMENTO vendem MENOS\n",
        "[1., 3.] Lojas com [maior sortimento/ competidores à + tempo] deveriam vender +."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JAeRmkO1diEg"
      },
      "outputs": [],
      "source": [
        "#[1., 3.] Lojas com [maior sortimento/ competidores à + tempo] deveriam vender +.\n",
        "aux1 = df4[['assortment', 'sales']].groupby('assortment').sum().reset_index()\n",
        "#soma de todas as vendas que tem o assortment do tipo ...\n",
        "sns.barplot(x='assortment', y='sales', data=aux1);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iO7sXw6ddiEg"
      },
      "source": [
        "#### assortment do tipo basic e o extended tem mais ou menos o mesmo tipo de vendas e o extra tem o volume de vendas bem menor\n",
        "supondo que o extra é o maior assortment vemos um tendencia decrescente\n",
        "Será que houve uma mudança do comportamento ao longo do tempo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aouAkx8udiEh"
      },
      "outputs": [],
      "source": [
        "# como o tempo, semanas do ano, afecta o fenomeno do assortment relativamente as vendas\n",
        "aux2 = df4[['year_week', 'assortment', 'sales']].groupby(['year_week','assortment']).sum().reset_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8mRAMug8diEh"
      },
      "outputs": [],
      "source": [
        "aux2.pivot(index='year_week', columns='assortment', values='sales').plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lxivimAgdiEh"
      },
      "outputs": [],
      "source": [
        "#o assortment extra sugere uma linha linear e horizontal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V61JE8oQdiEh"
      },
      "outputs": [],
      "source": [
        "aux3=aux2[aux2['assortment']=='extra']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R0Hs9tX2diEi"
      },
      "outputs": [],
      "source": [
        "\n",
        "aux3.pivot(index='year_week', columns='assortment', values='sales').plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJCFU3K8diEi"
      },
      "source": [
        "2.2. Lista Final de Hipóteses\n",
        "[0, 3.] Lojas com [0 / competidores à + tempo] deveriam vender +."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BDF0_NxmdiEi"
      },
      "source": [
        "[2., ] Lojas com competidores + próximo deveriam vender - ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipj12eEmdiEi"
      },
      "source": [
        "2.2. Lista Final de Hipóteses\n",
        "[1., 3.] Lojas com [maior sortimento/ competidores à + tempo] deveriam vender +."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSsTqTt2diEi"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "** Produtos **\n",
        "\n",
        "[4., 5., 6.] Lojas [promoções activas por mais tempo, com + [dias de promoção, promoções consecutivas]] deveriam vender +\n",
        "\n",
        "** Tempo **\n",
        "\n",
        "7. Lojas abertas durante o feriado de Natal deveriam vender menos.\n",
        "\n",
        "8. Lojas ao longo do ano deveriam vender mais.\n",
        "\n",
        "9. Lojas no segundo semestre do ano deveriam vender mais.\n",
        "\n",
        "10. Lojas depois do dia 10 de cada mes deveriam vender mais.\n",
        "\n",
        "11. Lojas nos finais de semana deveriam vender menos.\n",
        "\n",
        "12. Lojas nos Feriados escolares deveriam vender menos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-rz-2gRdiEi"
      },
      "source": [
        "#### **H2. Lojas com competidores + próximos deveriam vender menos.**\n",
        "#### **FALSA, Lojas com competidores + próximos deveriam vender mais.**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPBRbza6diEi"
      },
      "outputs": [],
      "source": [
        "#### **2.2. Lista Final de Hipóteses**\n",
        "#### **H1. Lojas com maior sortimento deveriam vender mais.**\n",
        "#### **FALSA, lojas com MAIOR SORTIMENTO vendem MENOS**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xmEz-uIJIfBJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LNrGYYiMIfBK"
      },
      "outputs": [],
      "source": [
        "df4.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xJ6dzidYdiEj"
      },
      "outputs": [],
      "source": [
        "com_dis='competition_distance'\n",
        "y = 'sales'\n",
        "\n",
        "bins = list(np.arange(0, 20000, 1000))\n",
        "com_dis_bin='competition_distance_binned'\n",
        "\n",
        "aux1[com_dis_bin]=pd.cut(df4[com_dis], bins=bins)\n",
        "aux2 = aux1[[com_dis_bin, y]].groupby(com_dis_bin).sum().reset_index()\n",
        "\n",
        "aux3=df4[[com_dis,y]].groupby(com_dis).sum().reset_index()\n",
        "plt.subplot(1,4,1)\n",
        "sns.barplot(x=com_dis_bin, y=y, data=aux2); #como são as vendas por cada distância\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "plt.subplot(1,4,2)\n",
        "sns.scatterplot(x=com_dis, y=y, data=aux3);\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "plt.subplot(1,4,3)\n",
        "x = sns.heatmap(aux3.corr(method='pearson'), annot=True);\n",
        "#bootom, top = x.get #AttributeError: 'Axes' object has no attribute 'get'\n",
        "# medir a força de correlação"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NkbsGjvadiEj"
      },
      "source": [
        "#### **H3. Lojas com competidores à + tempo deveriam vender +.**\n",
        "#competition_open_since, competition_time_month, competition_open_since_month, competition_open_since_year\n",
        "#### **False, lojas com COMPETIDORES à + tempo vendem MENOS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1Z_8N5LdiEj"
      },
      "outputs": [],
      "source": [
        "df4.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pButoMIJdiEj"
      },
      "outputs": [],
      "source": [
        "#competition_open_since_month\n",
        "com_ope_sin_mon='competition_open_since_month'\n",
        "y = 'sales'\n",
        "\n",
        "#bins = list(np.arange(0, 20000, 1000))\n",
        "#com_dis_bin='competition_distance_binned'\n",
        "#aux1[com_dis_bin]=pd.cut(aux1[com_dis], bins=bins)\n",
        "#aux2 = aux1[[com_dis_bin, y]].groupby(com_dis_bin).sum().reset_index()\n",
        "\n",
        "aux3=df4[[com_ope_sin_mon,y]].groupby(com_ope_sin_mon).sum().reset_index()\n",
        "plt.subplot(1,4,1)\n",
        "sns.barplot(x=com_ope_sin_mon, y=y, data=aux3);\n",
        "#plt.xticks(rotation=90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ngE05RhdiEj"
      },
      "outputs": [],
      "source": [
        "#competition_open_since_month\n",
        "comp_tim_mon='competition_time_month'\n",
        "y = 'sales'\n",
        "\n",
        "#bins = list(np.arange(0, 20000, 1000))\n",
        "#com_dis_bin='competition_distance_binned'\n",
        "#aux1[com_dis_bin]=pd.cut(aux1[com_dis], bins=bins)\n",
        "#aux2 = aux1[[com_dis_bin, y]].groupby(com_dis_bin).sum().reset_index()\n",
        "\n",
        "aux1=df4[['competition_time_month',y]].groupby('competition_time_month').sum().reset_index()\n",
        "plt.subplot(1,4,1)\n",
        "\n",
        "\n",
        "#filtrando, todas as linhas e colunas, os primeiros 12 meses de competição e com tempo de competição diferente ao da realização da venda\n",
        "aux2 = aux1[( aux1['competition_time_month']<12) & (aux1[comp_tim_mon]!=0)]\n",
        "sns.barplot(x=comp_tim_mon, y=y, data=aux2);\n",
        "#plt.xticks(rotation=60)\n",
        "\n",
        "plt.subplot(1,4,2)\n",
        "#exite alguma tendencia de crescimento?\n",
        "sns.regplot(x=comp_tim_mon, y=y, data=aux2);\n",
        "\n",
        "plt.subplot(1,4,3)\n",
        "#sns.heatmap(x='competition_time_month', y=y, data=aux2);\n",
        "#em termos de relevância para o modelo,\n",
        "# é relevante pois tem uma correlação não tão próxima de zero\n",
        "x = sns.heatmap(aux1.corr(method='pearson'), annot=True);\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pe2NqJ6XdiEk"
      },
      "outputs": [],
      "source": [
        "#Quanto + recente forem as competições, a abertura das lojas do competidores, maior são as suas vendas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nd208xPHdiEk"
      },
      "source": [
        "#### **H4. Lojas com promoções activas por mais tempo, com + dias de promoção, deveriam vender + **\n",
        "#### Falsa, lojas com promoções activas por mais tempo vendem menos, depois de um certo período de promoção\n",
        "#### vende regularmente até um certo tempo, depois decai\n",
        "#### validar a hipotese vs\n",
        "#### a variável é relevante para o modelo ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qyCbWvGjdiEk"
      },
      "outputs": [],
      "source": [
        "#### **H4. Lojas promoções activas por mais tempo, com + dias de promoção deveriam vender + o **\n",
        "df4[['date','promo','is_promo','promo2', 'promo2_since_week','promo2_since_year', 'promo_since', 'promo_time_week']].sample(15)\n",
        "#df4.sample()#.co\n",
        "#['promo2', 'promo2_since_week',\t'promo2_since_year', 'promo_since', 'promo_time_week']\n",
        "aux1=df4[['promo_time_week','sales']].groupby('promo_time_week').sum().reset_index()\n",
        "sns.barplot(x='promo_time_week', y='sales', data=aux1);\n",
        "#promo_since\tpromo_time_week\n",
        "#promo2\tpromo2_since_week\tpromo2_since_year"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y-oXu-gPdiEl"
      },
      "outputs": [],
      "source": [
        "y='promo_time_week'\n",
        "x='sales'\n",
        "aux2=aux1[aux1['promo_time_week']>0] # Promo extendido\n",
        "aux3=aux1[aux1['promo_time_week']<0] # Promo regular, tradicional\n",
        "\n",
        "#plt.subplot(1,2,1)\n",
        "#sns.barplot(x='promo_time_week', y='sales', data=aux2, label='Promo extendido ');\n",
        "#plt.xticks(rotation=90);\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "sns.barplot(x='promo_time_week', y='sales', data=aux3, label='Promo regular, tradicional');\n",
        "#plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=90);\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.barplot(x='promo_time_week', y='sales', data=aux2, label='Promo extendido ');\n",
        "plt.xticks(rotation=90);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7ghFtGFdiEl"
      },
      "outputs": [],
      "source": [
        "plt.subplot(2,1,2)\n",
        "sns.barplot(x='promo_time_week', y='sales', data=aux2, label='Promo extendido ');\n",
        "plt.xticks(rotation=90);\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "sns.barplot(x='promo_time_week', y='sales', data=aux3, label='Promo regular, tradicional ');\n",
        "#plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=90);\n",
        "\n",
        "#plt.subplot(1,2,2)\n",
        "#sns.barplot(x='promo_time_week', y='sales', data=aux2, label='Promo extendido ');\n",
        "#plt.xticks(rotation=90);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a80UB48EdiEm"
      },
      "outputs": [],
      "source": [
        "# os gráficos acima sugerem uma tendência\n",
        "#verificando se realmente existe alguma tendência nos gráficos\n",
        "plt.subplot(1,2,1)\n",
        "sns.regplot(x='promo_time_week', y='sales', data=aux3, label='Promo regular, tradicional');\n",
        "#plt.subplot(1,2,1)\n",
        "plt.xticks(rotation=90);\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "sns.regplot(x='promo_time_week', y='sales', data=aux2, label='Promo extendido ');\n",
        "plt.xticks(rotation=90);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5v4oOcQdiEn"
      },
      "outputs": [],
      "source": [
        "# Procurando encontrar a força do comportamento da correlação, usado o método corr, obedecendo a formula de pearson 19:31,\n",
        "sns.heatmap(aux1.corr( method='pearson'), annot=True);\n",
        "# correlação de 0.029 é uma correlação muito fraca"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2bewO5jjdiEp"
      },
      "outputs": [],
      "source": [
        "# Procurando encontrar a força do comportamento da correlação, usado o método corr, obedecendo a formula de pearson 19:31,\n",
        "sns.heatmap(aux2.corr( method='pearson'), annot=True);\n",
        "# correlação de 0.029 é uma correlação negativa e forte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQ8vsjSBdiEp"
      },
      "outputs": [],
      "source": [
        "# Procurando encontrar a força da correlação, usado o método corr, obedecendo a formula de pearson 19:31,\n",
        "sns.heatmap(aux3.corr( method='pearson'), annot=True);\n",
        "# correlação de 0.94 é uma correlação positiva e muito forte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUiIpPmUIfCO"
      },
      "outputs": [],
      "source": [
        "# grid=gridspec.GridSpec(2,3) #2 linhas e 3 colunas\n",
        "grid=GridSpec(2,3) #2 linhas e 3 colunas\n",
        "\n",
        "plt.subplot(grid[0,0])\n",
        "# aux2=\n",
        "\n",
        "x='promo_time_week'\n",
        "y='sales'\n",
        "\n",
        "# ValueError: Could not interpret value `promo_time_week` for `x`. An entry with this name does not appear in `data`.\n",
        "# aux1.sample()\n",
        "sns.barplot(x=x, y=y, data=df4);\n",
        "#plt.xticks(rotation=90)\n",
        "\n",
        "plt.subplot(grid[0,1])\n",
        "sns.regplot(x=x, y=y, data=aux2);\n",
        "\n",
        "plt.subplot(grid[1,0])\n",
        "sns.barplot(x=x, y=y, data=aux3);\n",
        "\n",
        "plt.subplot(grid[1,1])\n",
        "sns.regplot(x=x, y=y, data=aux3);\n",
        "\n",
        "plt.subplot(grid[:,2])\n",
        "sns.heatmap(aux1.corr(method='pearson'), annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gs566y6dIfCP"
      },
      "outputs": [],
      "source": [
        "#aux3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7_UxtQEpdiEs"
      },
      "source": [
        "#### ** <s> H5. Lojas com + dias de promoção, deveriam vender + #### ** Tempo **  </s>\n",
        "#### ** H4. Lojas com promoções activas por mais tempo, com + dias de promoção, deveriam vender + **\n",
        "#### Falsa, lojas com promoções activas por mais tempo vendem menos, depois de um certo período de promoção\n",
        "#### vende regularmente até um certo tempo, depois decai\n",
        "#### validar a hipotese vs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PdcEKCTkdiEt"
      },
      "outputs": [],
      "source": [
        "df4.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iO4rNvqdiEt"
      },
      "source": [
        "#### **H6. Lojas com + dias de promoções consecutivas deveriam vender +\n",
        "#### ** FALSA ** , Lojas com + promoções consecutivas vendem menos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21Ql3pZhdiEt"
      },
      "outputs": [],
      "source": [
        "df4[['promo','promo2','sales']].groupby(['promo','promo2']).sum().reset_index().sort_values(by=['sales'], ascending=True) #df.sort_values(by=['Column_name'], ascending=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0swyVquvdiEt"
      },
      "outputs": [],
      "source": [
        "# a diferença existente entre as 4 vendas é significativa ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcOUwPqldiEu"
      },
      "outputs": [],
      "source": [
        "#será que ao longo do tempo, o comportamento das vendas mudou tendo activado as duas promoções, a regular e a tradicional?\n",
        "df4[((df4['promo']==1) & (df4['promo2']==1))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ4DVdB7diEu"
      },
      "outputs": [],
      "source": [
        "aux1=df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 1 )][['year_week', 'sales']]\n",
        "aux1.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NWXrK3bddiEu"
      },
      "outputs": [],
      "source": [
        "#agrupar, somar e fazer o reset_index\n",
        "aux2=df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 1 )][['year_week', 'sales']].groupby('year_week').sum().reset_index()\n",
        "aux2.plot()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3D-iO6jtNV1"
      },
      "outputs": [],
      "source": [
        "aux3=df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 0 )][['year_week', 'sales']].groupby('year_week').sum().reset_index()\n",
        "#ax = aux3.plot()\n",
        "aux4=df4[( df4['promo'] == 0 ) & ( df4['promo2'] == 0 )][['year_week', 'sales']].groupby('year_week').sum().reset_index()\n",
        "aux5=df4[( df4['promo'] == 0 ) & ( df4['promo2'] == 1 )][['year_week', 'sales']].groupby('year_week').sum().reset_index()\n",
        "ax = aux3.plot()\n",
        "aux2.plot(ax=ax)\n",
        "aux4.plot(ax=ax)\n",
        "aux5.plot(ax=ax)\n",
        "ax.legend(labels=(\"Tradicional & Extraordinario\",\"Tradicional\",\"Sem promoção\",\"Extraordinario\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnHCCNmZdiEv"
      },
      "source": [
        "#### ** H7. Lojas abertas durante o feriado de natal deveriam vender menos. **\n",
        "#### ** ** Verdade, Lojas abertas durante o feriado de natal vendem menos,\n",
        "#### quanto a relevância,\n",
        "#### mostra-se relevante dado o crescimento considerável de vendas para cada 1 dos feriados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xj3u-fsKIfCt"
      },
      "outputs": [],
      "source": [
        "march_dates = (\n",
        "        df4['date'].dt.month.eq(12) &\n",
        "        df4['date'].dt.day.between(25, 31)\n",
        ")\n",
        "april_dates = (\n",
        "        df4['date'].dt.month.eq(4) &\n",
        "        df4['date'].dt.day.between(1, 25)\n",
        ")\n",
        "m = march_dates #| april_dates\n",
        "\n",
        "filtered_df = df4[m][['date','sales']]#.groupby('date').sum().reset_index()\n",
        "filtered_df.plot(y='sales',x='date')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdaz9RPBIfCw"
      },
      "outputs": [],
      "source": [
        "march_dates = (\n",
        "        df4['date'].dt.month.eq(12) &\n",
        "        df4['date'].dt.day.between(25, 31)\n",
        ")\n",
        "april_dates = (\n",
        "        df4['date'].dt.month.eq(4) &\n",
        "        df4['date'].dt.day.between(1, 25)\n",
        ")\n",
        "m = march_dates #| april_dates\n",
        "\n",
        "filtered_df = df4[m][['date','sales']]#.groupby('date').sum().reset_index()\n",
        "filtered_df.plot(y='sales',x='date')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiPZorQPIfCy"
      },
      "outputs": [],
      "source": [
        "#df4[df4['state_holiday']!='regular_day'][['date','sales','state_holiday','school_holiday']].groupby('state_holiday').sum().reset_index()#.sample(5)\n",
        "#aux=df4[df4['state_holiday']!='regular_day'][['sales','state_holiday']].groupby('state_holiday').sum().reset_index()#.sample(5)\n",
        "#aux.plot(y='sales',x='state_holiday')\n",
        "#sns.catplot(kind=\"bar\", x='state_holiday',y='sales', data=aux)\n",
        "#\n",
        "#cols=pd.unique(df4['state_holiday'])\n",
        "aux2=df4[df4['state_holiday']!='regular_day'][['sales','state_holiday','year']].groupby('year').sum().reset_index()#.sample(5)\n",
        "#g =\n",
        "#sns.catplot(kind=\"bar\", x='year',y='sales', data=aux2, hue='state_holiday', alpha=.4, height=4) #label=cols )#'state_holiday')\n",
        "\n",
        "#RuntimeError: In draw_glyphs_to_bitmap: Could not convert glyph to bitmap (raster overflow; error code 0x62\n",
        "\n",
        "#g.fig.set_figheight(3.5)\n",
        "#g.fig.set_figwidth(3)AU\n",
        "\n",
        "#g.despine(left=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3jgaTNyIfCz"
      },
      "outputs": [],
      "source": [
        "aux3=df4[df4['state_holiday']!='regular_day'][['sales','state_holiday','year']].groupby(['state_holiday', 'year']).sum().reset_index()#.sample(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wJ8OOu4IfC0"
      },
      "outputs": [],
      "source": [
        "aux3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8keqOgTzIfC1"
      },
      "outputs": [],
      "source": [
        "aux2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4yz6JAmIfC2"
      },
      "outputs": [],
      "source": [
        "#ValueError: Could not interpret value `year` for `x`. An entry with this name does not appear in `data`.\n",
        "aux2.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "As39mD4TIfC4"
      },
      "outputs": [],
      "source": [
        "plt.subplot(2,1,1)\n",
        "#hue=\n",
        "#sns.catplot(kind=\"bar\", x='year',y='sales', data=aux2) #, alpha=.4, height=4) #label=cols )#'state_holiday')\n",
        "#sns.catplot(kind=\"bar\", x='year',y='sales', data=aux2) #, alpha=.4, height=4) #label=cols )#'state_holiday')\n",
        "#sns.barplot(x='year', y='sales', hue='state_holiday', data=aux2, alpha=0.7)\n",
        "\n",
        "#ValueError: Could not interpret value `year` for `x`. An entry with this name does not appear in `data`.\n",
        "#year_week\tsales\n",
        "#sns.barplot(x='year', y='sales', data=aux2, alpha=0.7)\n",
        "\n",
        "#ValueError: Could not interpret value `year_week` for `x`. An entry with this name does not appear in `data`.\n",
        "sns.barplot(x='year_week', y='sales', data=aux2, alpha=0.7)\n",
        "#ValueError: Could not interpret value `year` for `hue`. An entry with this name does not appear in `data`.\n",
        "plt.show()\n",
        "plt.subplot(2,1,2)\n",
        "#hue=\n",
        "#sns.catplot(kind=\"bar\", x='state_holiday',y='sales', data=aux3) #, alpha=.4, height=4) #label=cols )#'state_holiday')\n",
        "sns.barplot(x='state_holiday', y='sales', hue='year', data=aux3, alpha=0.7)\n",
        "\n",
        "#?? todo: to see sns.catplot vs sns.barplot\n",
        "#barplot\n",
        "#Show point estimates and confidence intervals using bars.\n",
        "#catplot\n",
        "#Combine a categorical plot with a FacetGrid.\n",
        "\n",
        "#?? todo: aux4:count, quantos feriados públicos temos/ano\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9glbhLsqdiEv"
      },
      "source": [
        "#### ** H8. Lojas ao longo do ano deveriam vender +\n",
        "#### ** ** Falsa, as lojas ao longo do ano vendem -\n",
        "#### Quanto a relevância,\n",
        "#### a variável ano é ou não relevante para o modelo\n",
        "#### existe uma variação acentuada das vendas ao longo dos anos?\n",
        "#### o ano de 2015 tem vendas de meses em falta\n",
        "#### o ano tem 12 meses contudo o 2015 tem vendas em apenas x meses\n",
        "#### que tal montar uma serie que identifica o data e consider as vendas e fazer uma previsão para os meses #### em falta, fazer as análises considerando os períodos idénticos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MZZ7GDW-IfC8"
      },
      "outputs": [],
      "source": [
        "#as vendas do ano 2015 terminam em Agosto, pode ser a causa de baixa venda comparando com os restantes anos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXnuUXXxIfC9"
      },
      "outputs": [],
      "source": [
        "#KeyError: 'year'\n",
        "#aux1=promo&promo2\n",
        "aux1=df4[( df4['promo'] == 1 ) & ( df4['promo2'] == 1 )][['year', 'sales']]\n",
        "aux1.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaaoiVcuIfC-"
      },
      "outputs": [],
      "source": [
        "#Falta o primeiro grafico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ywETplimIfC_"
      },
      "outputs": [],
      "source": [
        "aux2.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S8pVFtAzIfDC"
      },
      "outputs": [],
      "source": [
        "#KeyError: 'promo_time_week'\n",
        "aux2.sample()\n",
        "# de\n",
        "# year_week\tsales\n",
        "# para\n",
        "# year\tsales\tstate_holiday"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "652SkFTlIfDF"
      },
      "outputs": [],
      "source": [
        "# grid=gridspec.GridSpec(2,3) #2 linhas e 3 colunas\n",
        "grid=GridSpec(2,3) #2 linhas e 3 colunas\n",
        "\n",
        "plt.subplot(grid[0,0])\n",
        "# aux2=\n",
        "\n",
        "x='promo_time_week'\n",
        "y='sales'\n",
        "\n",
        "# ValueError: Could not interpret value `promo_time_week` for `x`. An entry with this name does not appear in `data`.\n",
        "# aux1.sample()\n",
        "##KeyError: 'year'\n",
        "sns.barplot(x=x, y=y, data=df4);\n",
        "#plt.xticks(rotation=90)\n",
        "\n",
        "#plt.subplot(1,3,1)\n",
        "#aux2=df4[df4['state_holiday']!='regular_day'][['sales','state_holiday','year']].groupby('year').sum().reset_index()#.sample(5)\n",
        "#g =\n",
        "#sns.catplot(kind=\"bar\", x='year',y='sales', data=df4) #aux2, )#hue='state_holiday', alpha=.4, height=4) #label=cols )#'state_holiday')\n",
        "#https://seaborn.pydata.org/examples/grouped_barplot.html\n",
        "\n",
        "plt.subplot(grid[0,1])\n",
        "##KeyError: 'promo_time_week'\n",
        "x='year_week'\n",
        "#year_week\tsales\n",
        "## The above exception was the direct cause of the following exception:\n",
        "## UFuncTypeError: ufunc 'multiply' did not contain a loop with signature matching\n",
        "## types (dtype('<U7'), dtype('float64')) -> None\n",
        "##trocar o tipo de grafico\n",
        "###sns.regplot(x=x, y=y, data=aux2);\n",
        "#plt.subplot(1,3,2)\n",
        "\n",
        "#KeyError: 'year'\n",
        "#sns.regplot(x='year', y='sales', data=aux1, label='Promo extendido ');\n",
        "\n",
        "\n",
        "#plt.xticks(rotation=90);\n",
        "\n",
        "\n",
        "#plt.subplot(grid[1,0])\n",
        "#sns.barplot(x=x, y=y, data=aux3);\n",
        "#ValueError: Could not interpret value `year_week` for `x`. An entry with this name does not appear in `data`.\n",
        "sns.barplot(x=x, y=y, data=aux2);\n",
        "\n",
        "plt.subplot(grid[0,2])\n",
        "#sns.regplot(x=x, y=y, data=aux3);\n",
        "\n",
        "#plt.subplot(grid[:,2])\n",
        "#sns.heatmap(aux1.corr(method='pearson'), annot=True)\n",
        "#plt.subplot(1,3,3)\n",
        "\n",
        "aux1=df4[['sales','year']].groupby('year').sum().reset_index()\n",
        "# aux1 todas as vendas independente do período\n",
        "# verificando o grau de correlação entre as variáveis year and sales\n",
        "sns.heatmap(aux1.corr(method='pearson'), annot=True);\n",
        "\n",
        "#g.fig.set_figheight(3.5)\n",
        "#g.fig.set_figwidth(3)\n",
        "\n",
        "#g.despine(left=True)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksRC31u0diEw"
      },
      "source": [
        "#### ** H9. Lojas no 2o semestre deveriam vender + #### ** **\n",
        "#### Falsa, as lojas no 2o semestre vendem -,\n",
        "#### cada 1 dos meses tem vendas inferiores a 5.0 no 1o semestre do acumulado de vendas por mês é superior a 5.0 logo\n",
        "#### as vendas do 1 semestre são superiores as do 2o semestre\n",
        "#### contudo, como o ano 2015 esta imcompleto, sugere-se a adicinas os meses de 1 -> 7,\n",
        "#### isto é fazer-se uma análise exploratória apenas com os dados dos anos 2013 e 2014, pois estão completos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHgKreBoIfDH"
      },
      "outputs": [],
      "source": [
        "#procurando valor do ano\n",
        "#df4['year'].sample()\n",
        "#não era necessário considerar os meses no intervalo de 1 a 12\n",
        "#aux=df4[df4['month'].between(1, 12)][['month','sales','year']].groupby(['year','month']).sum().reset_index()\n",
        "aux=df4[df4['month'].between(1, 12)][['month','sales','year']].groupby(['year','month']).sum().reset_index()\n",
        "#criar dois tipos de dados, anos completos e incompletos de  2015\n",
        "plt.subplot(4,1,1)\n",
        "sns.pointplot(x='year',y='sales', hue='month', data=aux)\n",
        "plt.subplot(4,1,2)\n",
        "sns.pointplot(x='year',y='sales',data=aux)\n",
        "\n",
        "aux1=df4[['month','sales','year']].groupby(['year','month']).sum().reset_index()\n",
        "plt.subplot(4,1,3)\n",
        "sns.pointplot(x='year',y='sales', hue='month', data=aux1)\n",
        "plt.subplot(4,1,4)\n",
        "sns.pointplot(x='year',y='sales',data=aux1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Tiv0j8OIfDI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B6N9TY4oIfDI"
      },
      "outputs": [],
      "source": [
        "#como ter informação do segundo semestre\n",
        "#df4.sample()\n",
        "#agrupar por mes\n",
        "plt.subplot(4,1,1)\n",
        "aux=df4[df4['month'].between(1, 12)][['month','sales','year']].groupby(['month','year']).sum().reset_index()\n",
        "#df4[df4['month'].between(1, 12)][['month','sales','year']].groupby('month').sum().reset_index()\n",
        "sns.pointplot(x='month',y='sales',data=aux)\n",
        "\n",
        "#considerar as vendas por ano\n",
        "plt.subplot(4,1,2)\n",
        "#agrupar por ano\n",
        "sns.pointplot(x='year',y='sales', hue='month',data=aux)\n",
        "semestre1=df4[df4['date'].dt.month.between(1, 6)][['month','sales','year']].groupby(['month','year']).sum().reset_index()\n",
        "semestre2=df4[df4['date'].dt.month.between(7, 12)][['month','sales','year']].groupby(['month','year']).sum().reset_index()\n",
        "#df4['date'].dt.month.between(1, 6)\n",
        "plt.subplot(4,1,3)\n",
        "sns.pointplot(x='month',y='sales',data=semestre1, label='primeiro semestre')\n",
        "\n",
        "plt.subplot(4,1,4)\n",
        "sns.pointplot(x='month',y='sales',data=semestre2, label='segundo semestre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQQqGzYVIfDJ"
      },
      "outputs": [],
      "source": [
        "#como ter informação do segundo semestre\n",
        "#df4.sample()\n",
        "#agrupar por mes\n",
        "plt.subplot(4,1,1)\n",
        "aux=df4[df4['month'].between(1, 12)][['month','sales','year']].groupby(['month','year']).sum().reset_index()\n",
        "#df4[df4['month'].between(1, 12)][['month','sales','year']].groupby('month').sum().reset_index()\n",
        "sns.pointplot(x='month',y='sales',data=aux)\n",
        "\n",
        "#considerar as vendas por ano\n",
        "plt.subplot(4,1,2)\n",
        "#agrupar por ano\n",
        "sns.pointplot(x='year',y='sales', hue='month',data=aux)\n",
        "semestre1=df4[df4['date'].dt.month.between(1, 6)][['month','sales','year']].groupby(['month','year']).sum().reset_index()\n",
        "semestre2=df4[df4['date'].dt.month.between(7, 12)][['month','sales','year']].groupby(['month','year']).sum().reset_index()\n",
        "#df4['date'].dt.month.between(1, 6)\n",
        "plt.subplot(4,1,3)\n",
        "sns.pointplot(x='month',y='sales',data=semestre1, label='primeiro semestre')\n",
        "\n",
        "plt.subplot(4,1,4)\n",
        "sns.pointplot(x='month',y='sales',data=semestre2, label='segundo semestre')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0yIt98AIfDK"
      },
      "outputs": [],
      "source": [
        "#os meses do ano 2015 sem vendas são de 8 a 12\n",
        "aux.sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjByuHvodiEw"
      },
      "source": [
        "#### ** H10. Lojas do dia 10 de cada mês deveriam vender + **\n",
        "#### ** **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rxg4EyvHIfDL"
      },
      "outputs": [],
      "source": [
        "#df4.sample()\n",
        "#linha vs coluna\n",
        "#vendas vs day\n",
        "day_sales=df4[['day','sales']].groupby('day').sum().reset_index()\n",
        "day_sales.sample()\n",
        "# todo: grafico de [barra ,regressão,correlação](day vs sales) e bara(before_or_after_10 vs sales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qeogzg47IfDM"
      },
      "outputs": [],
      "source": [
        "aux.sample(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGRdFf3tIfDN"
      },
      "outputs": [],
      "source": [
        "#quais os dados que temos?\n",
        "df4.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Fs0OFZ7IfDN"
      },
      "outputs": [],
      "source": [
        "\n",
        "#df4['after_or_before_10']=df4['day'].apply(lambda x: 'before' if x['day']<11 else 'after')\n",
        "#between\n",
        "#TypeError: 'int' object is not subscriptable\n",
        "# x['date'], TypeError: 'Timestamp' object is not subscriptable\n",
        "#apply\n",
        "#df2['state_holiday']=df2['state_holiday'].apply(lambda x: 'public holiday' if x=='a' else 'Easter holiday' if x=='b'  else 'Christmas' if x=='c' else 'regular_day')\n",
        "df4['after_or_before_10']=df4['day'].apply(lambda x: 'before' if x<=10 else 'after')\n",
        "df4['after_or_before_10']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-pr6p6zIfDP"
      },
      "outputs": [],
      "source": [
        "#como ter informação do segundo semestre\n",
        "#df4.sample()\n",
        "#agrupar por mes\n",
        "plt.subplot(4,1,1)\n",
        "#aux=df4[df4['day'].between(1, 12)][['day','month','sales','year']].groupby(['day','month','year']).sum().reset_index()\n",
        "aux=df4[df4['day'].between(1, 12)][['day','month','sales']].groupby(['day','month']).sum().reset_index()\n",
        "#df4[df4['month'].between(1, 12)][['month','sales','year']].groupby('month').sum().reset_index()\n",
        "#ValueError: Length of list vectors must match length of `data` when both are used,\n",
        "# but `data` has length 31 and the vector passed to `hue` has length 2\n",
        "sns.pointplot(x='day',y='sales',data=aux) #, hue=['month'])\n",
        "# ValueError: Length of list vectors must match length of `data` when both are used,\n",
        "# but `data` has length 31 and the vector passed to `hue` has length 1.\n",
        "\n",
        "#considerar as vendas por ano\n",
        "plt.subplot(4,1,2)\n",
        "#sns.pointplot(x='month',y='sales',data=aux, hue=['day'])\n",
        "#ValueError: Length of list vectors must match length of `data` when both are used,\n",
        "#but `data` has length 144 and the vector passed to `hue` has length 1.\n",
        "#agrupar por ano\n",
        "#sns.pointplot(x='year',y='sales', hue='month',data=aux)\n",
        "#apply\n",
        "\n",
        "#TypeError: 'int' object is not subscriptable\n",
        "df4['after_or_before_10']=df4['day'].apply(lambda x: 'before' if x['day']<11 else 'after')\n",
        "sales_until_10=df4[df4['date'].dt.day.between(1, 10)][['day','month','sales','year']].groupby(['day','month','year']).sum().reset_index()\n",
        "sales_after_10=df4[df4['date'].dt.day.between(11, 31)][['day','month','sales','year']].groupby(['day','month','year']).sum().reset_index()\n",
        "#df4['date'].dt.month.between(1, 6)\n",
        "plt.subplot(4,1,3)\n",
        "#sns.pointplot(x='day',y='sales',data=sales_until_10, label='sales until day 10', hue=['month','year'] )\n",
        "sns.pointplot(x='day',y='sales',data=sales_until_10, label='sales until day 10')#, hue=['month'] )\n",
        "\n",
        "plt.subplot(4,1,4)\n",
        "sns.pointplot(x='day',y='sales',data=sales_after_10, label='sales after day 10')#, hue=['year'] )\n",
        "#sns.pointplot(x='day',y='sales',data=sales_after_10, label='sales after dia 10', hue=['month','year'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHgGNk4OIfDQ"
      },
      "outputs": [],
      "source": [
        "#NameError: name 'sales_after_10' is not defined\n",
        "sales_after_10.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8zX2xO_4IfDS"
      },
      "outputs": [],
      "source": [
        "#sales_after_10=sales_after_10[['day','sales']].groupby(['day']).sum().reset_index()\n",
        "#sales_after_10=df4[df4['date'].dt.day.between(11, 31)][['day','month','sales','year']]\n",
        "#.groupby(['day','month','year']).sum().reset_index()\n",
        "#sales_until_10=sales_until_10[['day','sales']].groupby(['day']).sum().reset_index() # df4[df4['date'].dt.day.between(1, 10)][['day','month','sales','year']].groupby(['day','month','year']).sum().reset_index()\n",
        "#sales_after_10=df4[df4['date'].dt.day.between(11, 31)][['day','month','sales','year']].groupby(['day','month','year']).sum().reset_index()\n",
        "#df4['date'].dt.month.between(1, 6)\n",
        "plt.subplot(2,1,1)\n",
        "#sns.pointplot(x='day',y='sales',data=sales_until_10, label='sales until day 10', hue=['month','year'] )\n",
        "sns.barplot(x='day',y='sales',data=sales_until_10, label='sales until day 10')#, hue=['month'] )\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "sns.barplot(x='day',y='sales',data=sales_after_10, label='sales after day 10')#, hue=['year'] )\n",
        "#sns.pointplot(x='day',y='sales',data=sales_after_10, label='sales after dia 10', hue=['month','year'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fmv0xwZPIfDT"
      },
      "outputs": [],
      "source": [
        "#sales_after_10=sales_after_10[['day','sales']].sum().reset_index()\n",
        "\n",
        "#sales_until_10=sales_until_10[['day','sales']].sum().reset_index()\n",
        "\n",
        "plt.subplot(2,1,1)\n",
        "#sns.pointplot(x='day',y='sales',data=sales_until_10, label='sales until day 10', hue=['month','year'] )\n",
        "sns.countplot(x='day',data=sales_until_10, label='sales until day 10')#, hue=['month'] )\n",
        "#sns.countplot(x='day',y='sales',data=sales_until_10, label='sales until day 10')#, hue=['month'] )\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "#sns.countplot(x='day',y='sales',data=sales_after_10, label='sales after day 10')#, hue=['year'] )\n",
        "sns.countplot(x='day',data=sales_after_10, label='sales after day 10')#, hue=['year'] )\n",
        "#sns.pointplot(x='day',y='sales',data=sales_after_10, label='sales after dia 10', hue=['month','year'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KxDd-MfNIfDW"
      },
      "source": [
        "#### ** H10. Lojas aos finais de semana, deveriam vender -\n",
        "#### ** **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vAbzIVG7IfDX"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WdlBG1XhIfDY"
      },
      "source": [
        "#### ** H10. Lojas durante os feriados escolares deveriam vender -\n",
        "#### ** **"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_UNHG4CIfDZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPhAv-mOdiEw"
      },
      "source": [
        "#### ** H7. Lojas com + dias de promoções consecutivas deveriam vender + ** Tempo **\n",
        "#### ** H7. Lojas com competidores + próximos deveriam vender menos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLvsSIMidiEw"
      },
      "source": [
        "#### ** H7. Lojas com + dias de promoções consecutivas deveriam vender + ** Tempo **\n",
        "#### ** H7. Lojas com competidores + próximos deveriam vender menos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wTbDxcSQdiEx"
      },
      "source": [
        "#### **H2. Lojas com competidores + próximos deveriam vender menos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY_2tjSGdiEx"
      },
      "source": [
        "#### **H2. Lojas com competidores + próximos deveriam vender menos.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6F2iCE0fdiEx"
      },
      "source": [
        "#### [4., 5., 6.] Lojas [promoções activas por mais tempo, com + [dias de promoção, promoções consecutivas]] deveriam vender +\n",
        "** Tempo **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q_33E5QdiEz"
      },
      "source": [
        "### 4.3. Análise Multivariada"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPx8dg8EdiEz"
      },
      "source": [
        "#### **H4. Lojas com promoções activas por mais tempo, com + dias de promoção, deveriam vender + **\n",
        "#### Falsa, lojas com promoções activas por mais tempo vendem menos, depois de um certo período de promoção\n",
        "# vende regularmente até um certo tempo, depois decai\n",
        "# validar a hipotese vs\n",
        "# a variável é relevante para o modelo ?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FoY2eHPihgm"
      },
      "outputs": [],
      "source": [
        "#!git clone -b modulo04_exploratory_data_analysis --single-branch https://github.com/cabicho/ds_in_deploy.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t2DA2WNohV1Z"
      },
      "source": [
        "#fazer a importação de dum arquivo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jL_FMS8zGt-1"
      },
      "source": [
        "https://colab.research.google.com/drive/13QbpDpdiNgrvYkzvcEsup2ZUxcGKYUhO#scrollTo=3q_33E5QdiEz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_M_t0fnGzL9"
      },
      "source": [
        "# 5.0. PASSO 05 - DATA PREPARATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IvFWN6JbfEXb"
      },
      "outputs": [],
      "source": [
        "df5=df4.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6TVmD3PseKsB"
      },
      "source": [
        "##5.1 Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMdUGK3EeXII"
      },
      "source": [
        "##5.1 Rescaling\n",
        "# ??? month\tday day_of_week year_week-actualmente temos problemas nesta variável pois não é inteiro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5intuO52er6p"
      },
      "source": [
        "###Quais as variáveis que vamos aplicar o rescaling ? Whats variables will be apply rescaling?\n",
        "### Selecting numerical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ex6K0BBNefaE"
      },
      "outputs": [],
      "source": [
        "\n",
        "#qual a escala a ser usada, (Min-Max ou Robust) scaler\n",
        "#   year\t competition_time_month  promo_time_week competition_distance\n",
        "var_numerical=df5.select_dtypes(include=['int64','float64'])\n",
        "var_numerical.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfdQFBTnk-gk"
      },
      "outputs": [],
      "source": [
        "#df5.sample() # why year_week is not a numeric variable?\n",
        "# como convertemos o promo_time_week?\n",
        "#df2['promo_time_week']=((df2['date']-df2['promo_since'])/7).apply(lambda x: x.days).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QXJBT_jljnQh"
      },
      "outputs": [],
      "source": [
        "lista=[ 'year','competition_time_month','promo_time_week', 'competition_distance']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7UPsUBmWjjw7"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(df5[lista])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rW9qRD_O8bz"
      },
      "outputs": [],
      "source": [
        "lista_much_outliers = [ 'promo_time_week', 'competition_distance']\n",
        "lista_fews_outliers = ['year','competition_time_month']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csqBYZ5nLwYy"
      },
      "outputs": [],
      "source": [
        "#encontrado os parametros da fórmula e logo aplica nos dados, obtendo assim 1 nova variável mas na mesma escala\n",
        "rs  = RobustScaler()\n",
        "mms = MinMaxScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7LHftLEXQvsI"
      },
      "outputs": [],
      "source": [
        "# much outliers, muito discrepantes\n",
        "def trans_robust( i):\n",
        "    df5[i]=rs.fit_transform(df5[[i]].values)\n",
        "    df5[i].sample(5)\n",
        "\n",
        "for i in lista_much_outliers: #to range(len(lista)):\n",
        "  trans_robust(i) #lista[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZm_YX_AQBDJ"
      },
      "outputs": [],
      "source": [
        "#fews outliers, alguns valores discrepantes\n",
        "def trans_minmax( i):\n",
        "    df5[i]=mms.fit_transform(df5[[i]].values)\n",
        "    df5[i].sample(5)\n",
        "#lista_fews_outliers=['year','competition_time_month']\n",
        "for i in lista_fews_outliers: #to range(len(lista)):\n",
        "  trans_minmax(i) #lista[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6A6eqQIqdfj"
      },
      "outputs": [],
      "source": [
        "len(lista)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OGRxZ0PaNsGO"
      },
      "outputs": [],
      "source": [
        "#showing the distribution of variables\n",
        "lista = lista_much_outliers + lista_fews_outliers\n",
        "j=1\n",
        "for i in lista:\n",
        "  plt.subplot(len(lista)*2,1,j)\n",
        "  j=j+2\n",
        "  sns.histplot(df5[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM8yiO5BSGwk"
      },
      "outputs": [],
      "source": [
        "sns.boxplot(df5[lista])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neBwBx9tef3b"
      },
      "source": [
        "## 5.1 Normalization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEGhyClE-1gu"
      },
      "source": [
        "##5.3.1 Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HvX4an1acOAJ"
      },
      "outputs": [],
      "source": [
        "# https://towardsdatascience.com/all-about-categorical-variable-encoding-305f3361fd02\n",
        "#1.7\n",
        "cat_attributes = df5.select_dtypes(exclude=['int64', 'float64', 'datetime64[ns]']) #include=['object']\n",
        "obj_attributes = df5.select_dtypes(include=['object']) #include=['object']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31hx-dxSAlxr"
      },
      "outputs": [],
      "source": [
        "#StateHoliday - indicates a state holiday. Normally all stores, with few exceptions,\n",
        "#are closed on state holidays. Note that all schools are closed on public holidays and weekends.\n",
        "#a = public holiday, b = Easter holiday, c = Christmas, 0 = None\n",
        "df5=pd.get_dummies(df5, prefix=['state_holiday'], columns=['state_holiday'])\n",
        "\n",
        "#StoreType - differentiates between 4 different store models: a, b, c, d\n",
        "#store_type = [a,b,c], existe uma ordem?, está em falra o re,\n",
        "# que tal adicionar o feriado escolar com um dos dias esta na mesma variável que os restantes feriados\n",
        "#trocando letras por números\n",
        "le = LabelEncoder()\n",
        "df5['store_type']=le.fit_transform(df5['store_type']) #trocando letras por números\n",
        "\n",
        "#Assortment - describes an assortment level: a = basic, b = extra, c = extended,  exite um ordem => 3) Ordinal Encoding\n",
        "assort_dict = {'basic':1, 'extra':2, 'extended':3}\n",
        "#update values of assortment to ordinal encoding\n",
        "df5['assortment']=df5.assortment.map(assort_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86OBaN23Rmcc"
      },
      "outputs": [],
      "source": [
        "df5.assortment.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beAFsqwH_BSS"
      },
      "source": [
        "##5.3.2 Response Variable Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b4816h9RMS_"
      },
      "outputs": [],
      "source": [
        "sns.displot(df5.sales)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naZOQHnORWBx"
      },
      "outputs": [],
      "source": [
        "#df5.sales = np.loglp.df5.sales\n",
        "df5.sales = np.log1p(df5.sales)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjNW_Q-p-Dgw"
      },
      "outputs": [],
      "source": [
        "sns.displot(df5.sales) #o grafico já apresenta uma distribuição mais próxima da normal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNfAodosgRrj"
      },
      "source": [
        "##5.3.3 Nature Transformation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACdBSNeiUokX"
      },
      "outputs": [],
      "source": [
        "\n",
        "#day_week, day, moth, year, week_year\n",
        "#https://medium.com/@axelazara6/why-we-need-encoding-cyclical-features-79ecc3531232\n",
        "new_values=[]\n",
        "# to help function 5.3.3 Nature Transformation\n",
        "def encode(data, col, max_val):\n",
        "  sin_= col+'_sin'\n",
        "  new_values.append(sin_)\n",
        "  #data[col+'_sin']=np.sin(2*np.pi*data.col)/max_val\n",
        "  #df5['day_of_week_sin'] = df5['day_of_week'].apply( lambda x: np.sin( x * ( 2. *np.pi/7 ) ) )\n",
        "  data[sin_]=np.sin(2*np.pi*data[col])/max_val\n",
        "  cos_ = col+'_cos'\n",
        "  new_values.append(cos_)\n",
        "  #data[col+'_cos']=np.cos(2*np.pi*data.col)/max_val\n",
        "  data[cos_]=np.cos(2*np.pi*data[col])/max_val\n",
        "  return data\n",
        "  #print(sin_, cos_)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "65GELNFJPDxX"
      },
      "outputs": [],
      "source": [
        "df5.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa61nUZbFXBY"
      },
      "outputs": [],
      "source": [
        "# because 'year_week':52 then => can't multiply sequence by non-int of type 'float'\n",
        "#dict_lista={'day_of_week':7, 'month':12, 'day':30, 'year_week':52} #,#day:31 como maximo ?, 60 week_for_year? <=max(12)meses/ano * max(5)semanas/mes #'competition_time_month'}\n",
        "#df6=df5.copy() # todo coment\n",
        "#listing variables to be transformed\n",
        "dict_lista={'day_of_week':7, 'month':12, 'day':30} #, 'year_week':52} 356 days of year by 7 days of week then 52 weeks by year, every 52 weeks we have 1 year\n",
        "for key, value in dict_lista.items():\n",
        "  df5=encode(df5.copy(), key, value) #chante to df5\n",
        "  #encode(df5, key, value)\n",
        "  #print(key, value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ONfA8Px7SZPu"
      },
      "outputs": [],
      "source": [
        "#df6.sample()\n",
        "#df6[new_values].sample() # chanche to df5\n",
        "df5[new_values].sample() # chanche to df5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "towmDEYxsNPB"
      },
      "source": [
        "# 6.0. PASSO 06 - FEATURE SELECTION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViVZS9RhtS1D"
      },
      "outputs": [],
      "source": [
        "#df7=df6.copy() #\n",
        "df6=df5.copy()\n",
        "#df7[new_values].sample() #\n",
        "df6[new_values].sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5J66qw9wVKC"
      },
      "outputs": [],
      "source": [
        "#list(dict_lista.keys()) #+new_values\n",
        "#no_in_dic_lista=['day_of_week','promo_since','competition_since','year_week'] #\"['competition_since'] not in index\"\n",
        "no_in_dic_lista=['day_of_week','promo_since','year_week']\n",
        "dict_lista_final=list(dict_lista.keys())+no_in_dic_lista\n",
        "#df8=df7.copy()\n",
        "#df8=df8.drop(dict_lista_final)\n",
        "#df8[dict_lista_final].sample()\n",
        "df6[dict_lista_final].sample()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lM_jq4xwVvW"
      },
      "source": [
        "## 6.1. Split Dataframe Into Training and Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMEr_IqRw6Yn"
      },
      "outputs": [],
      "source": [
        "cols_drop = dict_lista_final\n",
        "df6 = df6.drop(cols_drop, axis=1)\n",
        "df6.sample()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzZWAkWx9ENR"
      },
      "outputs": [],
      "source": [
        "day=df6[['date','store']].groupby('store').max().reset_index()['date'][0]\n",
        "day #Timestamp('2013-01-01 00:00:00')\n",
        "datetime.timedelta(days=6*7) #datetime.timedelta(days=42)\n",
        "max_date_train = day-datetime.timedelta(days=6*7)\n",
        "max_date_train#[0] # = min_date_test Timestamp('2012-11-20 00:00:00')\n",
        "\n",
        "# training dataset\n",
        "df6_train = df6[df6['date']< max_date_train] #df6['date']< '2015-06-05'] #max_date_train\n",
        "#df6[df6_train].sample()\n",
        "df6_train.sample(10) #608130, 969198\n",
        "X_train = df6_train.copy()\n",
        "y_train = X_train['sales']\n",
        "\n",
        "# test dataset\n",
        "df6_test = df6[df6['date']>= max_date_train] #df6['date']< '2015-06-05'] #max_date_train\n",
        "#df6[df6_train].sample()\n",
        "df6_test.sample(10) # 2015-07-17\n",
        "X_test = df6_test.copy()\n",
        "y_test = X_test['sales']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q5WOOIS_UfWo"
      },
      "outputs": [],
      "source": [
        "print('Train Min Date: {}'.format(df6_train.date.min()))\n",
        "print('Train Max Date: {}'.format(df6_train.date.max()))\n",
        "\n",
        "print('\\nTest Min Date: {}'.format(df6_test.date.min()))\n",
        "print('Test Max Date: {}'.format(df6_test.date.max()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjkhY2oVwpZ3"
      },
      "source": [
        "## 6.1. Boruta as Feature Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7d79LLGly-WA"
      },
      "outputs": [],
      "source": [
        "#fd6_train.sample()\n",
        "\n",
        "#df6 = df6.drop(cols_drop, axis=1)\n",
        "#df6_train.sample(10)[['date','sales']]\n",
        "x_train_n = df6_train.drop(['date','sales'], axis=1).values\n",
        "y_train_n = df6_train['sales'].values.ravel() # para colocar dentro de 1 vector\n",
        "\n",
        "df6_test.drop(['date','sales'], axis=1).values #sample(10) # 2015-07-17\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRlo10R3w7dI"
      },
      "outputs": [],
      "source": [
        "#define train and test dataset for Boruta\n",
        "#x_train_n\n",
        "#y_train_n\n",
        "\n",
        "x_train_n = df6_train.drop(['date','sales','competition_open_since','competition_distance'], axis=1).values\n",
        "#df6_train.dtypes\n",
        "\n",
        "y_train_n = df6_train['sales'].values.ravel() # para colocar dentro de 1 vector\n",
        "print(\" x_train_n.dtype {}, y_train_n.dtype {}\".format(x_train_n.dtype,y_train_n.dtype))\n",
        "df6_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQ2gZ0JJ_lNU"
      },
      "outputs": [],
      "source": [
        "# define RandomForestRegressor\n",
        "rf = RandomForestRegressor(n_jobs=-1)#(n_jobs=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HSCCPaawusr"
      },
      "outputs": [],
      "source": [
        "x_train_n #.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pQa8IFTNwu83"
      },
      "outputs": [],
      "source": [
        "y_train_n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OU7h3_UmwN-7"
      },
      "outputs": [],
      "source": [
        "# define Boruta\n",
        "# Mascarando dtypes para rodar o boruta\n",
        "#np.float = float\n",
        "#np.int = int\n",
        "#np.object = object\n",
        "#np.bool = bool\n",
        "#boruta = BorutaPy(rf, n_estimators='auto', verbose=2, random_state=42).fit(x_train_n, y_train_n)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfCx2dTUmVau"
      },
      "outputs": [],
      "source": [
        "#cols_selected = boruta.support_.tolist()\n",
        "#cols_selected #\n",
        "#cols_selected = boruta.support_.tolist()cols_selected\n",
        "\n",
        "cols_selected =[True,True, False, False, True, True, True, True, False, True, False, False, False, True, True, False, False, False, False, False, False, False, False, False, False]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlqhYiHECBrW"
      },
      "source": [
        "### 6.2.1. Best Features from Boruta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DaDN1Va8Arsq"
      },
      "outputs": [],
      "source": [
        "#best features\n",
        "#X_train_fs = X_train.drop(['date','sales'], axis=1) df6_train\n",
        "X_train_fs = df6_train.drop(['date','sales','competition_open_since','competition_distance'], axis=1)\n",
        "#IndexError: Boolean index has wrong length: 25 instead of 26\n",
        "cols_selected_boruta = X_train_fs.iloc[:, cols_selected].columns.to_list()\n",
        "cols_selected_boruta #.sample() #AttributeError: 'list' object has no attribute 'sample'\n",
        "# [1:'store',2:'promo',3:'store_type',4:'assortment',5:'competition_open_since_month',6:'competition_open_since_year',7:'promo2_since_week',8:'competition_time_month',9:'promo_time_week']\n",
        "# H3. Lojas com competidores à + tempo deveriam vender +.# **False, lojas com COMPETIDORES à + tempo vendem MENOS\n",
        "# 4-9:'competition_open_since_month' mostrou-se relevante para o modelo, 5-8:'competition_open_since_year'\n",
        "#**H6. Lojas com + dias de promoções consecutivas deveriam vender +, ** FALSA ** , Lojas com + promoções consecutivas vendem menos\n",
        "# 2-9: 'promo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRyJSAviNduP"
      },
      "outputs": [],
      "source": [
        "#not selected boruta\n",
        "cols_not_selected_boruta = list(np.setdiff1d(X_train_fs.columns, cols_selected_boruta))\n",
        "cols_not_selected_boruta #['day_cos','day_of_week_cos','day_of_week_sin','day_sin','id','is_promo','month_cos','month_sin','promo2',\n",
        " #'promo2_since_year','school_holiday','state_holiday_Christmas','state_holiday_Easter holiday','state_holiday_public holiday','state_holiday_regular_day','year']\n",
        "#X_train_fs.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5my_mKMvIK9Y"
      },
      "outputs": [],
      "source": [
        "#feature to add\n",
        "feature_to_add = ['date','sales']\n",
        "\n",
        "# final features\n",
        "#cols_selected_boruta.extend(feature_to_add)\n",
        "\n",
        "#cols_selected_boruta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFvAuR8xIK9Y"
      },
      "source": [
        "# 7.0. PASSO 07 - MACHINE LEARNING MODELLING"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s-VWqaBWIK9Y"
      },
      "outputs": [],
      "source": [
        "x_train = X_train[cols_selected_boruta] #X_train[cols_selected_boruta]\n",
        "x_test = X_test[cols_selected_boruta]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.sample()"
      ],
      "metadata": {
        "id": "3FYrDAy7Qb7T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_vCAVmAIK9Y"
      },
      "source": [
        "## 7.1. Average Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LhQodB4eIK9Y"
      },
      "outputs": [],
      "source": [
        "aux1=x_test.copy()\n",
        "\n",
        "#add sales collumns\n",
        "aux1['sales']=y_test.copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction\n",
        "# calcu avarage salling of each of the stores\n",
        "aux2=aux1[['store','sales']].groupby('store').mean().reset_index().rename(columns={'sales':'predictions'})"
      ],
      "metadata": {
        "id": "5A-h8FHFPFkR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aux1 = pd.merge(aux1, aux2, how='left', on='store')\n",
        "yhat_baseline = aux1['predictions']"
      ],
      "metadata": {
        "id": "EwdNRjMNSKFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#performance\n",
        "baseline_result = ml_error('Average Model', np.expm1(y_test), np.expm1(yhat_baseline))"
      ],
      "metadata": {
        "id": "YC4htZ_nTDM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_result"
      ],
      "metadata": {
        "id": "Kp2Dc9N4lNbu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-ZlJOHtIK9Z"
      },
      "source": [
        "## 7.2. Linear Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "lr = LinearRegression().fit(x_train, y_train)\n",
        "\n",
        "# prediction\n",
        "yhat_lr = lr.predict(x_test)\n",
        "\n",
        "# performance\n",
        "lr_result = ml_error('Linear Regression', np.expm1(y_test), np.expm1(yhat_lr))\n",
        "lr_result #.RMSE[0] #2744.045828082333\n",
        "# if lr_result.RMSE[0]> baseline_result.RMSE[0] os dados tem comportamento complexo, não linear"
      ],
      "metadata": {
        "id": "ink3Vybv_5Ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# o erro do modelo linear regression(2744.045828) é maior que o erro do modelo de média(1843.604875)"
      ],
      "metadata": {
        "id": "kIIPfdHkFiOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvoiVg-pIK9Z"
      },
      "source": [
        "## 7.3. Linear Regression Regularized Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "lrr = Lasso(alpha=0.01).fit(x_train, y_train)\n",
        "\n",
        "# prediction\n",
        "yhat_lrr = lrr.predict(x_test)\n",
        "\n",
        "# performance\n",
        "lrr_result = ml_error('Linear Regression - Lasso', np.expm1(y_test), np.expm1(yhat_lrr))\n",
        "lrr_result #.RMSE[0] #2744.045828082333\n",
        "# if lr_result.RMSE[0]> baseline_result.RMSE[0] os dados tem comportamento complexo, sendo pior que da regressão linear normal\n",
        "# por tando dos 3 modelos o da média mostrou-se melhor com erro de RMSE menor (1843.604875) que os restantes dois"
      ],
      "metadata": {
        "id": "Zr2gYm6_C2he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.4. Random Forest Regressor"
      ],
      "metadata": {
        "id": "DfhKTNOte2Rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#import\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# model\n",
        "rfr = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42).fit(x_train, y_train)\n",
        "\n",
        "# prediction\n",
        "yhat_rfr = rfr.predict(x_test)\n",
        "\n",
        "# performance\n",
        "rfr_result = ml_error('Ramdom Forest Regressor', np.expm1(y_test), np.expm1(yhat_rfr))\n",
        "rfr_result #.RMSE[0] #2744.045828082333\n",
        "# if lr_result.RMSE[0]> baseline_result.RMSE[0] os dados tem comportamento complexo, sendo pior que da regressão linear normal\n",
        "# por tando dos 3 modelos o da média mostrou-se melhor com erro de RMSE menor (1843.604875) que os restantes dois"
      ],
      "metadata": {
        "id": "Ww-FX1Z3p32D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.5. XGBoost Regressor"
      ],
      "metadata": {
        "id": "71SOt0cVfuAu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/usr/local/lib/python3.10/dist-packages/xgboost/core.py:160: UserWarning: [22:54:18] WARNING: /workspace/src/learner.cc:742:\n",
        "#Parameters: { \"colsample_bytee\" } are not used.\n",
        "#  warnings.warn(smsg, UserWarning)\n",
        "\n",
        "#import\n",
        "import xgboost as xgb\n",
        "\n",
        "# model\n",
        "model_xgbr = xgb.XGBRegressor(\n",
        "            objective='reg:squarederror',\n",
        "            n_estimators=100,\n",
        "            eta=0.01,\n",
        "            max_depth=10,\n",
        "            subsample=0.7,\n",
        "            colsample_bytee=0.9).fit(x_train, y_train)\n",
        "\n",
        "# prediction\n",
        "yhat_xgbr = model_xgbr.predict(x_test)\n",
        "\n",
        "# performance\n",
        "rgbr_result = ml_error('XGBoost Regressor', np.expm1(y_test), np.expm1(yhat_xgbr))\n",
        "rgbr_result #.RMSE[0] #2744.045828082333\n",
        "# if lr_result.RMSE[0]> baseline_result.RMSE[0] os dados tem comportamento complexo, sendo pior que da regressão linear normal\n",
        "# por tando dos 3 modelos o da média mostrou-se melhor com erro de RMSE menor (1843.604875) que os restantes dois"
      ],
      "metadata": {
        "id": "ExwyPmeRDdoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7.6. Compare Model's Performance"
      ],
      "metadata": {
        "id": "jlz5B-kxTuEg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "modelling_result = pd.concat([baseline_result, lr_result, lrr_result, rfr_result, rgbr_result])\n",
        "modelling_result.sort_values('RMSE')"
      ],
      "metadata": {
        "id": "83Lm_blNTpRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#feature to add\n",
        "#feature_to_add = ['date','sales']\n",
        "cols_selected_boruta_full=[]\n",
        "cols_selected_boruta_full=cols_selected_boruta.extend(feature_to_add)\n",
        "x_training = df6_train[cols_selected_boruta]##cols_selected_boruta_full] #.drop(['date','sales'], axis=1).values\n"
      ],
      "metadata": {
        "id": "O5WgtT6ZTluO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cols_selected_boruta) #_full)#] cols_selected_boruta_full) #None"
      ],
      "metadata": {
        "id": "Iwlyo8inBMgl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_training.sample()"
      ],
      "metadata": {
        "id": "mqzRT0mEBAsJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_training = df6[cols_selected_boruta] #X_train[cols_selected_boruta]\n",
        "x_training.shape#()"
      ],
      "metadata": {
        "id": "5AWzGSHypDW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "  #print('{MAE CV:' + np.round( np.mean(mae_list), 2).astype(str),\n",
        "  #                      'MAPE CV:'+ np.round( np.mean(mape_list), 2).astype(str) )\n",
        "\n",
        "#a = cross_validation(x_training, 6)\n",
        "#(x_training, kfold):\n",
        "#try_go()\n",
        "model=LinearRegression()\n",
        "#criar uma lista e um ciclo for\n",
        "\n",
        "model_name='Linear Regression'\n",
        "model = Lasso(alpha=0.01)#.fit(x_train, y_train)\n",
        "\n",
        "# prediction\n",
        "#yhat_lrr = lrr.predict(x_test)\n",
        "\n",
        "# performance\n",
        "#lrr_result = ml_error('Linear Regression - Lasso', np.expm1(y_test), np.expm1(yhat_lrr))\n",
        "model_name='Linear Regression - Lasso'\n",
        "## performance\n",
        "#rgbr_result = ml_error('XGBoost Regressor', np.expm1(y_test), np.expm1(yhat_xgbr))\n",
        "model_name = 'XGBoost Regressor'\n",
        "model = xgb.XGBRegressor(\n",
        "            objective='reg:squarederror',\n",
        "            n_estimators=100,\n",
        "            eta=0.01,\n",
        "            max_depth=10,\n",
        "            subsample=0.7,\n",
        "            colsample_bytee=0.9) #.fit(x_train, y_train)\n",
        "# model\n",
        "#rfr = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42).fit(x_train, y_train)\n",
        "\n",
        "# prediction\n",
        "#yhat_rfr = rfr.predict(x_test)\n",
        "\n",
        "# performance\n",
        "#rfr_result = ml_error('Ramdom Forest Regressor', np.expm1(y_test), np.expm1(yhat_rfr))\n",
        "\n",
        "model_name='Ramdom Forest Regressor'\n",
        "model = RandomForestRegressor(n_estimators=100, n_jobs=-1, random_state=42)\n",
        "\n",
        "a = cross_validation(x_training, 6, model_name, model)\n",
        "a"
      ],
      "metadata": {
        "id": "BivnyNIW4wVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.0. PASSO 08 - HYPERPARAMETER FINE TUNING"
      ],
      "metadata": {
        "id": "ZGo5i7dsFO0d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.1. Random Search"
      ],
      "metadata": {
        "id": "ncXNaA1oFyAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "param = {\n",
        "    'n_estimators'    : [1500, 1700, 2500, 3000, 3500],\n",
        "              'eta'   : [0.01, 0.03],\n",
        "          'max_depth' : [3, 5, 9],\n",
        "          'subsample' : [0.1, 0.5, 0.7],\n",
        "    'colsample_bytee' : [0.3, 0.7, 0.9],\n",
        "  'min_child_weight'  : [3,8,15]}\n",
        "\n",
        "MAX_EVAL = 2\n"
      ],
      "metadata": {
        "id": "YeLtmXvSIPMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import\n",
        "#import xgboost as xgb\n",
        "for i in range(MAX_EVAL):\n",
        "  #choose values for parameters randomly\n",
        "  hp = { k: random.sample(v,1)[0] for k,v in param.items()}\n",
        "  print(hp)\n",
        "  # model\n",
        "  model_xgbr = xgb.XGBRegressor(\n",
        "              objective='reg:squarederror',\n",
        "              n_estimators=hp['n_estimators'],\n",
        "              eta=hp['eta'],\n",
        "              max_depth=hp['max_depth'],\n",
        "              subsample=hp['subsample'],\n",
        "              colsample_bytee=hp['colsample_bytee'],\n",
        "              min_child_weight=hp['min_child_weight']) #.fit(x_train, y_train)\n",
        "\n",
        "  # prediction\n",
        "  yhat_xgbr = model_xgbr.predict(x_test)\n",
        "\n",
        "  # performance\n",
        "  rgbr_result = ml_error('XGBoost Regressor', np.expm1(y_test), np.expm1(yhat_xgbr))\n",
        "  rgbr_result #.RMSE[0] #2744.045828082333\n"
      ],
      "metadata": {
        "id": "0CcGhepSGgQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8.2. Final model"
      ],
      "metadata": {
        "id": "LSsMhdiWGF2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TVMJlJKaF4gA"
      }
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "SFbO_3n5FwB4",
        "t8_Ql6npdiC-",
        "lSa6L5ILdiDO",
        "UrbVwGmCdiDP",
        "CJYFGfOndiDS",
        "HWnH2oL9diDa",
        "yRvYZktMdiD1",
        "NZkO89h_diD3",
        "265VeFaodiD5",
        "oorEli6cdiEC",
        "fMcwVztudiEF",
        "kBt7vXrHdiEZ",
        "90CBF88ZIfA8",
        "QWFRDS4KdiEg",
        "iO7sXw6ddiEg",
        "s-rz-2gRdiEi",
        "NkbsGjvadiEj",
        "nd208xPHdiEk",
        "7_UxtQEpdiEs",
        "1iO4rNvqdiEt",
        "SnHCCNmZdiEv",
        "9glbhLsqdiEv",
        "ksRC31u0diEw",
        "cjByuHvodiEw",
        "KxDd-MfNIfDW",
        "WdlBG1XhIfDY",
        "3q_33E5QdiEz",
        "t2DA2WNohV1Z"
      ],
      "history_visible": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}